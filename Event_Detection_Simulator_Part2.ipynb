{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mojtabaSefidi/AI-Challenge-PoliceVsThieves/blob/main/Event_Detection_Simulator_Part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0ixs3gMPfGS"
      },
      "source": [
        "### Transfer models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRHGMTDmM09M",
        "outputId": "5c5cbc10-324d-4c8d-a07f-f2c4885879f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-0MG6rCa5AQ6dPtrUidUfeJHylPL5yDg\n",
            "To: /content/Game_svm_model\n",
            "100% 82.2M/82.2M [00:00<00:00, 191MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-HgI1mb5jbkb1i4VI2W4PTYY8Y0Fno41\n",
            "To: /content/Celebrity_cnn_model.h5\n",
            "100% 45.2M/45.2M [00:00<00:00, 182MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-OCf407ReepZCkfvUgMz8KenONSHaLfl\n",
            "To: /content/Celebrity_cnn_model.json\n",
            "100% 216M/216M [00:01<00:00, 113MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-cCzYqWrCDGKbqj5Xev4ThKrCZlzJsT7\n",
            "To: /content/Crypto_cnn_model.h5\n",
            "100% 89.3M/89.3M [00:02<00:00, 42.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-f5QutmN4naWXr9QrUrPFZEu4cNwDbQY\n",
            "To: /content/Crypto_cnn_model.json\n",
            "100% 446M/446M [00:05<00:00, 77.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-hPu5kBd-JH1AZtpmt8w_u3NApisUIr7\n",
            "To: /content/Environment_cnn_model.h5\n",
            "100% 70.2M/70.2M [00:02<00:00, 29.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-nZWLtt1Usma-xck5sBMt5bBgitQWfVO\n",
            "To: /content/Celebrity_svm_model\n",
            "100% 43.5M/43.5M [00:00<00:00, 145MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-rEC97bYZsTHNUakToXk2KMgWy91V26R\n",
            "To: /content/Environment_cnn_model.json\n",
            "100% 347M/347M [00:03<00:00, 88.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-yEaABqJeZMSCk9zqwYneSZJva_XGJ8Q\n",
            "To: /content/Game_cnn_model.h5\n",
            "100% 84.9M/84.9M [00:01<00:00, 60.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=105TGQiKlz4BW_WWzbeeuf2b5gz9ray2v\n",
            "To: /content/Game_cnn_model.json\n",
            "100% 423M/423M [00:04<00:00, 96.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13CqDRtZLxz0ZXZlikIiXjqaGwEi31Uiu\n",
            "To: /content/Crypto_svm_model\n",
            "100% 87.0M/87.0M [00:00<00:00, 181MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1c0l-7E_lpflVa5DTBAA3qVzBBFQxgx2T\n",
            "To: /content/Environment_svm_model\n",
            "100% 70.1M/70.1M [00:00<00:00, 140MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --no-cache-dir gdown -q\n",
        "!gdown 1-0MG6rCa5AQ6dPtrUidUfeJHylPL5yDg\n",
        "!gdown 1-HgI1mb5jbkb1i4VI2W4PTYY8Y0Fno41\n",
        "!gdown 1-OCf407ReepZCkfvUgMz8KenONSHaLfl\n",
        "!gdown 1-cCzYqWrCDGKbqj5Xev4ThKrCZlzJsT7\n",
        "!gdown 1-f5QutmN4naWXr9QrUrPFZEu4cNwDbQY\n",
        "!gdown 1-hPu5kBd-JH1AZtpmt8w_u3NApisUIr7\n",
        "!gdown 1-nZWLtt1Usma-xck5sBMt5bBgitQWfVO\n",
        "!gdown 1-rEC97bYZsTHNUakToXk2KMgWy91V26R\n",
        "!gdown 1-yEaABqJeZMSCk9zqwYneSZJva_XGJ8Q\n",
        "!gdown 105TGQiKlz4BW_WWzbeeuf2b5gz9ray2v\n",
        "!gdown 13CqDRtZLxz0ZXZlikIiXjqaGwEi31Uiu\n",
        "!gdown 1c0l-7E_lpflVa5DTBAA3qVzBBFQxgx2T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LDWO4NjOdtn",
        "outputId": "fdb817a4-abd0-4dbc-9daf-0d26e765fb6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/Event_Detection_Models/Celebrity_cnn_model.h5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import shutil\n",
        "shutil.move(\"/content/Crypto_svm_model\", \"/content/gdrive/MyDrive/Event_Detection_Models\")\n",
        "shutil.move(\"/content/Crypto_cnn_model.json\", \"/content/gdrive/MyDrive/Event_Detection_Models\")\n",
        "shutil.move(\"/content/Crypto_cnn_model.h5\", \"/content/gdrive/MyDrive/Event_Detection_Models\")\n",
        "\n",
        "shutil.move(\"/content/Environment_svm_model\", \"/content/gdrive/MyDrive/Event_Detection_Models\")\n",
        "shutil.move(\"/content/Environment_cnn_model.json\", \"/content/gdrive/MyDrive/Event_Detection_Models\")\n",
        "shutil.move(\"/content/Environment_cnn_model.h5\", \"/content/gdrive/MyDrive/Event_Detection_Models\")\n",
        "\n",
        "shutil.move(\"/content/Game_svm_model\", \"/content/gdrive/MyDrive/Event_Detection_Models\")\n",
        "shutil.move(\"/content/Game_cnn_model.json\", \"/content/gdrive/MyDrive/Event_Detection_Models\")\n",
        "shutil.move(\"/content/Game_cnn_model.h5\", \"/content/gdrive/MyDrive/Event_Detection_Models\")\n",
        "\n",
        "shutil.move(\"/content/Celebrity_svm_model\", \"/content/gdrive/MyDrive/Event_Detection_Models\")\n",
        "shutil.move(\"/content/Celebrity_cnn_model.json\", \"/content/gdrive/MyDrive/Event_Detection_Models\")\n",
        "shutil.move(\"/content/Celebrity_cnn_model.h5\", \"/content/gdrive/MyDrive/Event_Detection_Models\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjmLd8KFafKP"
      },
      "source": [
        "### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlAIr3hKkfVr",
        "outputId": "5e961a69-8340-4867-9170-103f6debca42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haJgbMelaqGH"
      },
      "source": [
        "### Import & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmWnO-4U39yy",
        "outputId": "2355b99d-0289-4e7d-fd56-30ca617c0b38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter, OrderedDict\n",
        "import operator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "import random\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SR0zNjgWoHYT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing import text, sequence\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation,Flatten\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, AveragePooling1D, GlobalAveragePooling1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing import text, sequence\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import svm\n",
        "import pickle\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JLqBfsYnCfs",
        "outputId": "fb1007de-5a48-4138-cb5f-9a690326d034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.7.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.13.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.21.6)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.21.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.1.97)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.64.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.12.1+cu113)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.9.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.12.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence_transformers) (3.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.6.15)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (1.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence_transformers\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "t4Jh1BN0oxWS"
      },
      "outputs": [],
      "source": [
        "# !pip install keybert[all]\n",
        "# from keybert import KeyBERT\n",
        "# kw_model = KeyBERT()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TT696ztGlEOk",
        "outputId": "57e28522-9b74-44c4-bae7-924cb78518ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: hazm in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: nltk==3.3 in /usr/local/lib/python3.7/dist-packages (from hazm) (3.3)\n",
            "Requirement already satisfied: libwapiti>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from hazm) (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1LDlffCuIatgoCKlxGInTh8W3b1fYgJ_y \n",
            "\n",
            "unzip:  cannot find or open resources.zip, resources.zip.zip or resources.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!pip install hazm\n",
        "from hazm import *\n",
        "from hazm import stopwords_list\n",
        "!gdown 1LDlffCuIatgoCKlxGInTh8W3b1fYgJ_y\n",
        "!unzip resources.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Pars_Bert_Model = SentenceTransformer('HooshvareLab/bert-base-parsbert-uncased',device='cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4D1Nf-228mX",
        "outputId": "b7321709-b3c8-4937-dc44-28c98ccdf5e0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/HooshvareLab_bert-base-parsbert-uncased. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/HooshvareLab_bert-base-parsbert-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBiC_-_2a7jN"
      },
      "source": [
        "## Define Positive , Negative & Spam Key-Phrases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NioYnygWlzf"
      },
      "source": [
        "### Stop Words & Spam Key Phrase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "q_NzoPGnXmQd"
      },
      "outputs": [],
      "source": [
        "stop_words = set(['زیرا','از','به','در','چه','پس','ولی','چون','یا','نیز','را','و', 'هم' , 'اگر' ,'تا' ,'اما' , 'که', 'با', 'اگرچه', 'آن', 'این', 'اکنون','همین','همان','چنانچه','آ‌نگاه','چنانچه','چنانچه','بر','لایک', 'برای','است','آیا'])\n",
        "\n",
        "spam_keyphrase = ['پادکست','نظرسنجی','تلگرام','ترکیب']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihTbRnJtXcSm"
      },
      "source": [
        "### Sport Key-Phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6hEGiRVFXpul"
      },
      "outputs": [],
      "source": [
        "list_of_sport_positive_keyphrase = [\n",
        "                           ['مدال','طلا'],['مدال','برنز'],['مدال','نقره'],\n",
        "                           ['مسابقه','فینال'],['تیم','قهرمانی','مسابقات'],\n",
        "                           ['ورزشکار','محرومیت'],['تیم','قهرمانی','جام'],\n",
        "                           ['دوپینگ','تست','مثبت'],['تیم','قهرمان','مسابقات'],\n",
        "                           ['بازیکن','توافق','تیم'],['ساله','قرارداد','توافق'],['امضای','قرارداد'],\n",
        "                           ['فسخ','قرارداد','کرد'],['فسخ','قرارداد','شد'],['قرارداد','تمدید','کرد'],\n",
        "                           ['انتقالات','نقل','بمب','توافق'],['انتقالات','نقل','بمب','پیوست'],\n",
        "                           ['قرضی','قرارداد'],['جایزه','بهترین'],['برگزاری','مسابقات'],\n",
        "                           ['لغو','مسابقات'],['تعویق','مسابقات'],['برگزار','مسابقات'],\n",
        "                           ['رکورد','گینس'],['رکورد','المپیک','شکسته'],['رکورد','جهان','شکسته'],\n",
        "                           ['رکورد','آسیا','شکسته'],['رکورد','المپیک','شکست'],\n",
        "                           ['رکورد','جهان','شکست'],['رکورد','آسیا','شکست'],\n",
        "                           ['رکورد','شکسته','شد'],['رکورد','به','حمله'],['در','یک','قدمی'],\n",
        "                           ['پناهجو','ورزشکار'],['پناهنده'],['هاله','از','ابهام'],['همکاری','قطع'],\n",
        "                           ['اخراج','سرمربی'],['استعفا','سرمربی'],['شد','سرمربی','موقت'],\n",
        "                           ['بار','اولین','برای'],['ستاره','درخشش'],['باورنکردنی'],\n",
        "                           ['بانوان','استادیوم'],['مصدومیت','شدید'],['مسابقات','صعود'],['کرد','سقوط'],\n",
        "                           ['رقابت','صعود'],['تست','کرونای','مثبت'],['کسب','سهمیه'],\n",
        "                           ['تست','کرونا','مثبت'],['کمیته','انضباطی','رای'],['کمیته','انضباطی','اخضار'],\n",
        "                           ['محرومیت','انضباطی'],['شعار','هواداران'],['اعتراض','هواداران'],\n",
        "                           ['اعتراض','شدید'],['محرومیت','ساله'],['پرونده','جریمه'],['شد','قطعی'],\n",
        "                           ['خداحافظی','هواداران'],['خداحافظی','تیم'],['وداع','تیم'],['در','قدمی','یک'],\n",
        "                           ['فوت','کرد'],['فوت','شد'],['در','جدایی','آستانه'],['گل','آقای','شد'],\n",
        "                           ['پزشکی','تست'],['راهی','بیمارستان'],['شد','بیهوش'],['تیغ','جراحی'],['تیغ','جراحان'],\n",
        "                           ['شد','رونمایی'],['کرد','رونمایی'],['میلیون','طلب'],['منصوب','شد'],\n",
        "                           ['طلا','توپ','برنده'],['طلا','کفش','برنده'],['هواداران','هجوم'],\n",
        "                           ['میادین','بازگشت','به'],['میادین','دوری','از'],['تاریخی','رکورد'],\n",
        "                           ['لو','رفت'],['مشخص','شد','تاریخ'],['مشخص','شد','قیمت'],['شد','تصویب'],\n",
        "                           ['مشخص','شد','جانشین'],['مشخص','شد','سرمربی'],['مشخص','شد','لیست'],['مشخص','شد','زمان'],\n",
        "                           ['مشخص','شد','قهرمان'],['مشخص','شدند','نفرات','برتر'],['مشخص','شد','نتایج'],['ناباورانه'],\n",
        "                           ['شدید','اعتراض'],['شدید','انتقاد'],['فوری'],['کشور','ثالث','بازی'],['شدید','درگیری'],\n",
        "                           ['قلبی','ایست'],\n",
        "                                 \n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzfOvmZWW49y"
      },
      "source": [
        "### Technology Key-Phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TlbE_tfZX0v8"
      },
      "outputs": [],
      "source": [
        "list_of_technology_positive_keyphrase = [\n",
        "                           ['جدید','منتشر','نسخه'],['رونمایی','نسخه'],\n",
        "                           ['سایبری','حمله'],['هک','شد'],['حمله','هکر'],\n",
        "                           ['حمله','هکرها'],['اطلاعات','افشای'],['لو','رفت'],\n",
        "                           ['لو','رفتن'],['برگزار','رویداد'],['بار','اولین','برای'],\n",
        "                           ['ماهواره'],['نوآوری','جدید'],['رونمایی','شد'],\n",
        "                           ['رونمایی','کرد'],['تاریخ','عرضه'],['معرفی','شد'],\n",
        "                           ['غول','فناوری'],['گروه','هکری'],['آپدیت','بزرگ'],\n",
        "                           ['حفره','امنیتی'],['آپدیت','جدید'],['اختلال'],['باگ','امنیتی'],\n",
        "                           ['نفوذ','سایبری'],['پشتیبانی','میکند'],['عرضه','شد'],['عرضه','میشود'],\n",
        "                           ['جدید','سری'],['ارز','نیمایی'],['خرید','شرکت'],['کرد','شکایت'],\n",
        "                           ['سرویس','فعال'],['سرویس','جدید'],['قابلیت','جدید'],['با','حضور'],\n",
        "                           ['افتتاح','مراسم'],['میلیون','دلار'],['راه','اندازی','کرد'],['نسخه','آزمایشی'],\n",
        "                           ['معرفی','بهترین'],['فناوری','جدید'],['منصوب','شد'],['مدل','جدید'],\n",
        "                           ['عملکرد','بهبود'],['آپدیت','بهبود'],['نسل','جدید','معرفی'],['افزایش','امنیت'],\n",
        "                           ['جدیدترین','رونمایی'],['انتشار','نسخه'],['شرکت','سهام','افزایش'],['شرکت','سهام','رشد'],\n",
        "                           ['گوشی','پرچمدار','معرفی'],['گوشی','پرچمدار','عرضه'],['گوشی','پرچمدار','منتشر'],\n",
        "                           ['گوشی','پرچمدار','عرضه'],['فوری'],['افزایش','قیمت'],['کاهش','قیمت'],['چشمگیر'],\n",
        "                           ['تریلیون','ارزش'],['گمرکی','نرخ'],['مجهز','شد'],['جدید','تکنولوژی'],['بروزرسانی','جدید'],\n",
        "                           ['روز','جدید','رسانی'],['جدید','امکانات'],['گجت','هوشمند'],['معرفی','محصول','جدید'],\n",
        "                           ['تاریخی','رکورد'],['استقبال','چشمگیر'],['استقبال','چشمگیر'],['مشخص','شد','تاریخ'],\n",
        "                           ['مشخص','شد','قیمت'],['مشخص','شد','زمان'],['تخصصی','نمایشگاه'],['خارج','دسترس','شد'],\n",
        "                           ['تولید','توقف'],['کرد','تکذیب'],['رقابت','معرفی'],['شد','تصویب'],\n",
        "                           ['رکورد','گینس'],['رکورد','شکست'],['رکورد','فروش'],['گزارش','مالی','منتشر'],\n",
        "                           ['جدید','پلتفرم'],['کرد','متحول'],['جدید','پلتفرم'],['شد','متحول'],['بزرگ','آپدیت'],\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RQwJqwjW5Cj"
      },
      "source": [
        "### Art Key-Phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cDABXp1TX2Uc"
      },
      "outputs": [],
      "source": [
        "list_of_art_positive_keyphrase = [\n",
        "['سکانس','منتشر'],['سکانس','انتشار'],['فیلم','انتشار'],['سریال','انتشار'],['فیلم','منتشر'],['سریال','منتشر'],\n",
        "['پیکر','تشییع'],['تشییع','خاکسپاری'],['بازیگران','فیلم','منتشر'],['انیمیشن','فروش'],['فیلم','فروش'],['سریال','فروش'],\n",
        "['فیلم','اکران'],['کاهش','کانون','عضو'],['فیلم','درآمد'],['دار','فانی','وداع'],['فوت','کرد'],['فوت','شد'],['سینما','گرفتار'],\n",
        "['فیلم','ممنوع'],['سریال','ممنوع'],['شرکت','جشنواره'],['کنسرت','لغو'],['برگزار','برنامه'],['مجوز','کنسرت'],['مجوز','فیلم'],\n",
        "['مجوز','اکران'],['سریال','جدید'],['فیلم','جدید'],['اکران','تعویق'],['نمایش','عمومی','تعویق'],['برنامه','تولید'],['مسابقه','تولید'],\n",
        "['مسابقه','تقلب'],['تولید','منتشر'],['ساخت','آثار'],['سریال','پخش'],['فیلم','پخش'],['کنسرت','برگزار'],['برگزاری','کنسرت'],\n",
        "['بازگشت','تلویزیون'],['ساخت','محصولات','طنز'],['ساخت','محصولات','کمدی'],['انتقاد','سینما'],['قطعه','موسیقی','منتشر'],\n",
        "['قطعه','موسیقی','پخش'],['برنده','جایزه','بهترین'],['سینما','اکران'],['ابطال','مجوز'],['تعلیق','مجوز'],['اعتراض','واکنش'],\n",
        "['برگزاری','جشنواره'],['انتخاب','بهترین'],['سینما','خداحافظی'],['تلویزیون','خداحافظی'],['انتشار','کتاب'],['کتاب','منتشر'],\n",
        "['انتشار','مجله','هنری'],['مجله','هنری','منتشر'],['بازدید','نمایشگاه'],['مراسم','برگزار'],['واکنش','هنرمندان'],\n",
        "['قیمت','بلیت','سینما'],['کمبود','کتابفروشی'],['استعدادیابی','موسیقی'],['استعدادیابی','خوانندگی'],['استعدادیابی','بازیگری'],\n",
        "['فروش','آثار','هنری'],['حذف','صدا','سیما'],['فیلم','ایفا','نقش'],['سریال','ایفا','نقش'],['ساخت','سریال'],\n",
        "['ساخت','فیلم'],['سانسور','سکانس'],['سانسور','فیلم'],['سانسور','سریال'],['ساخت','موسیقی'],['انتشار','موسیقی'],\n",
        "['موسیقی','پخش'],['فعالیت','آغاز'],['وارد','سینماشد'],['قیمت','بلیت','کنسرت'],['انتشار','اشعار'],['انتشار','شعر'],\n",
        "['کتاب','حراج'],['فروش','کتاب'],['کتاب','صادر'],['اشعار','انتقاد'],['ترجمه','کتاب'],['تحلیل','فیلم'],\n",
        "['تحلیل','سریال'],['تحلیل','کتاب'],['چاپ','اثر'],['چاپ','آثار'],['انتخاب','اعضا','شورا'],['تور','کنسرت'],\n",
        "['میلیون','دلار'],['میلیارد','دلار'],['صدرنشین','فروش'],['رکورد','فروش'],['سرسام','آوری'],['سرسام','آور'],\n",
        "['معرفی','شد'],['معرفی','کرد'],['تحسین','برانگیزی'],['تحسین','برانگیز'],['بهترین','سال'],['اهدای','جوایز'],\n",
        "['اهدا','کرد'],['پشتیبانی','میکند'],['پشتیبانی','می‌کند'],['پشتیبانی','میکنند'],['پشتیبانی','می‌کنند'],['نسخه','فروش'],\n",
        "['رکورد','فروش'],['میلیون','کاربر'],['میلیون','فروش'],['میلیارد','فروش'],['به‌روزرسانی'],['پشتیبانی','کرد'],\n",
        "['منتشر','شد'],['منتشر','کرد'],['منتشر','میشود'],['منتشر','می‌شود'],['پرفروش‌ترین‌'],['کاهش','تقاضا'],['افزایش','تقاضا'],\n",
        "['رسمی'],['لو','رفت'],['خرید','شرکت'],['تاریخ','انتشار'],['رونمایی'],['اعتراض'],['تعطیل','شد'],['هزینه','میلیون'],\n",
        "['هزینه','میلیارد'],['انتشار','اولین','تصاویر'],['برگزاری','حراجی'],['شایعه'],['برگزاری','رویداد'],['برگزار','رویداد'],['کشف','حجاب'],\n",
        "['مهاجرت','کرد'],['پناهنده','شد'],['تاخیر','خورد'],['حالت','تعلیق'],['حذف','شد'],['حذف','شدند'],['حذف','کرد'],['انتشار','بیانیه‌'],\n",
        "['انتشار','بیانیه‌ای'],['خرید','کمپانی'],['مالکیت','دست','داد'','],['فاش','شد'],['فاش','کرد'],['فاش','شدند'],['عذرخواهی','کرد'],\n",
        "['عذرخواهی','کردند'],['شایعات'],['افشای','اطلاعات'],['موفقیت','خیره‌کننده'],['دستمزد','نجومی'],['ممنوع','الکار'],['موفقیت','غیرمنتظره‌'],\n",
        "['تحریم','کرد'],['تحریم','شد'],['خرید','استودیو'],['فروش','استودیو'],['تصاحب','کرد'],['تصمیم','جنجالی'],['درگیری','شدید'],\n",
        "['استقبال','شدید'],['استقبال','چشمگیر'],['استقبال','چشم‌گیر'],['حاضر','مصاحبه','نشد'],['انتقاد','شدید'],['ممنوع','شد'],['تحریم','کرد'],\n",
        "['تحریم','شد'],['منصوب','کرد'],['منصوب','شد'],['منصوب','شدند'],['انتصاب'],['برکنار','شد'],['برکنار','کرد'],['اخراج','شد'],\n",
        "['اخراج','کرد'],['تصویب','شد'],['تصویب','کرد'],['تخلف','محرز'],['اختلاس'],['تغییرات','مدیریتی'],['اسرع','وقت'],['برخورد','متخلفان'],\n",
        "['اقدامات','قانونی'],['برخورد','جدی'],['برگزاری','نمایشگاه'],['برگزار','نمایشگاه'],['برگزاری','رویداد'],['برگزار','رویداد'],['افتتاح'],\n",
        "['تفاهم‌نامه','امضا'],['توافق','کرد'],['اولین','رسمی'],['آغاز','عرضه'],['پایان','عرضه'],['امضای','توافق','نامه'],['امضای','توافقنامه'],\n",
        "['امضای','توافق‌نامه'],['استقبال','بینظیر'],['استقبال','بی‌نظیر'],['استقبال','بی','نظیر'],['پلمپ','شد'],['پلمپ','کرد'],['آتش','سوزی'],['آتش‌سوزی'],\n",
        "['حریق','دچار']\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z8pPJwZW5IC"
      },
      "source": [
        "### Health Key-Phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YKoHGQc8X4mc"
      },
      "outputs": [],
      "source": [
        "list_of_health_positive_keyphrase = [\n",
        "    ['واردات','دارو'],['مستقر','شدند'],['مستقر','شده'],['وزیر','بهداشت'],['اعزام','پزشکان'],['اعزام','بازرسان'],\n",
        "    ['اعزام','بیماران'],['معاون','وزارت','بهداشت'],['معاون','وزیر','بهداشت'],['کنگره','برگزار','میشود'],\n",
        "    ['کنگره','برگزار','شده'],['کنگره','برگزار','شد'],['کنگره','برگزار','شود'],['جشنواره','برگزار','میشود'],\n",
        "    ['جشنواره','برگزار','شده'],['جشنواره','برگزار','شد'],['جشنواره','برگزار','شود'],['رئیس','سازمان','غذا','دارو'],\n",
        "    ['توزیع','واکسن'],['منصوب','کرد'],['منصوب','شد'],['افتتاح'],['بازدید','از','بیمارستان'],['بازدید','از','پروژه'],\n",
        "    ['پروژه','نیمه','کاره'],['قاچاق','دارو'],['ارسال','محموله'],['اهدای','دارو'],['اهدای','محموله'],['تسلیت','گفت'],\n",
        "    ['کمک','های','بشر','دوستانه'],['کشته','شدن'],['کشته','شدند'],['آماده','باش'],['تنش','آبی'],['اهدای','آب','آشامیدنی'],\n",
        "    ['کمیته','انضباطی'],['لغو','پروانه'],['نامه','اعتراضی'],['وقوع','حادثه'],['اعزام','تیم','نجات'],['اعزام','گروه','نجات'],\n",
        "    ['انتقال','به','منطقه','امن'],['منتقل','منطقه','امن'],['وقوع','حادثه'],['مدیریت','بحران'],['تشکیل','جلسه'],\n",
        "    ['پیدا','شدن','پیکر'],['مفقود','شدن'],['مفقود','شدند'],['واردات','واکسن'],['ممنوع','شدن'],['شناسایی','بیمار'],\n",
        "    ['جان','باخت'],['جان','باختند'],['امضای','تفاهم','نامه'],['تولید','دارو'],['برای','اولین','بار'],['تامین','دستگاه'],\n",
        "    ['تامین','تجهیزات'],['مناطق','محروم'],['روند','کاهشی'],['روند','افزایشی'],['رئیس‌جمهور'],['رئیس‌','جمهور'],['رییس‌جمهور'],\n",
        "    ['رییس‌','جمهور'],['مهار','شد'],['مهار','شدند'],['همه','گیری','بیماری'],['همه','گیری','ویروس'],['اختصاص','بودجه'],\n",
        "    ['پرداخت','هزینه'],['تصویب','شد'],['تصویب','رسید'],['تصویب','شدند'],['کاهش','فوتی'],['افزایش','فوتی'],['کشور','برتر','دنیا'],\n",
        "    ['طبق','اعلام','سازمان'],['کاهش','هزینه'],['افزایش','هزینه'],['اجرا','شدن','سراسری'],['اجرا','کردن','سراسری'],\n",
        "    ['اجرا','کنیم','سراسری'],['اجرای','سراسری'],['رکورد','بینظیر'],['رکورد','بی','نظیر'],['رکورد','بی‌نظیر'],['کاهش','مرگ','میر'],\n",
        "    ['افزایش','مرگ','میر'],['نخستین','مورد','ابتلا'],['اجرای','طرح'],['تحریم','دارو'],['صادرات','دارو'],['صادرات','واکسن'],\n",
        "    ['دارو','وارد','شد'],['دارو','وارد','کرد'],['دارو','صادر','کرد'],['دارو','صادر','شد'],['بهره','برداری'],['تقدیر','شد'],\n",
        "    ['تقدیر','کرد'],['امضای','تفاهم‌نامه'],['ورود','محموله'],['خارج','محموله'],['خروج','محموله'],['قابل','تحسین'],['حمایت','طرح'],\n",
        "    ['تشکیل','کمیته'],['پرداخت','بدهی'],['خبر','داد'],['بازدید','پروژه'],['قوی','ترین','قدرت','منطقه'],['قوی‌ترین','قدرت','منطقه'],\n",
        "    ['تصویب','آئین','نامه'],['دچار','مشکل'],['ضرورت','تقویت'],['ضرورت','تشکیل'],['بهترین','حوزه'],['تسلیت','گفت'],['فوت','کرد'],\n",
        "    ['فوت','شد'],['حادثه','دلخراش'],['حادثه','دل','خراش'],['حادثه','دل‌خراش'],['وقوع','حادثه'],['محدودیت','جدید'],['فرصت','جبران'],\n",
        "    ['خطوط','قرمز','وزارت'],['خط','قرمز','وزارت'],['ضروری','است'],['راه','اندازی','سامانه'],['راه','اندازی','سیستم'],['موظف','اجرای'],\n",
        "    ['موظف','اعطای'],['اختصاص','بودجه'],['تخصیص','بودجه'],['افزایش','تحت','پوشش'],['رسیدن','خودکفایی'],['خودکفایی','می‌رسیم'],\n",
        "    ['خودکفایی','می‌','رسیم'],['تاسیس','میشوند'],['تاسیس','شدند'],['تاسیس','شد'],['لزوم','اجرای'],['افزایش','موارد','ابتلا'],['اقدامات','تحسین','برانگیز']\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0euC6vyW5Nq"
      },
      "source": [
        "### Economy Key-Phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yuL7UFJiX7z3"
      },
      "outputs": [],
      "source": [
        "list_of_economy_positive_keyphrase = [\n",
        "                           ['شد','گران'],['شد','ارزان'],\n",
        "                           ['قیمت','کاهش'],['قیمت','افزایش'],\n",
        "                           ['نرخ','کاهش','تورم'],['نرخ','افزایش','تورم'],\n",
        "                           ['نرخ','کاهش'],['نرخ','افزایش'],\n",
        "                           ['تقاضا','افزایش'],['تقاضا','کاهش'],\n",
        "                           ['عرضه','افزایش'],['عرضه','کاهش'],\n",
        "                           ['حذف','یارانه'],['اقتصاد','وزیر'],['رشد', 'اقتصادی'],\n",
        "                           ['مهار', 'تورم'],['کنترل', 'تورم'],['رشد', 'صادرات'],\n",
        "                           ['واردات', 'رشد'],['واردات', 'کاهش'],['کاهش', 'صادرات'],\n",
        "                           ['نرخ', 'تورم'],['تولید', 'سقوط'],['تولید', 'کاهش'],['تولید', 'افزایش'],\n",
        "                           ['کاهش', 'قیمت'],['افزایش', 'قیمت'],['رشد', 'قیمت'],['شاخص', 'کل', 'رشد'],\n",
        "                           ['شاخص', 'کل', 'افزایش'],['شاخص', 'کل', 'افت'],['شاخص', 'کل', 'کاهش'],\n",
        "                           ['شاخص', 'کل', 'مثبت'],['شاخص', 'کل', 'منفی'],['شاخص', 'هم' ,'وزن', 'رشد'],\n",
        "                           ['شاخص', 'هم' ,'وزن', 'افزایش'],['شاخص', 'هم', 'وزن', 'افت'],['شاخص', 'هم' ,'وزن', 'کاهش'],\n",
        "                           ['شاخص', 'هم' ,'وزن', 'مثبت'],['شاخص', 'هم' ,'وزن', 'منفی'],\n",
        "                           ['ارزش', 'معاملات', 'بورس'],['ارزش', 'معاملات', 'خرد'],\n",
        "                           ['سرمایه', 'گذاری', 'اقتصاد'],['رشد', 'تجارت'],['کاهش', 'تجارت'],['رشد', 'تقاضا'],\n",
        "                           ['رشد', 'عرضه'],['رشد', 'کسب' , 'کار'],['افزایش', 'تقاضا'],['افزایش', 'عرضه'],\n",
        "                           ['افزایش', 'کسب' ,'کار'],['کاهش', 'تقاضا'],['کاهش', 'عرضه'],['کاهش', 'کسب' , 'کار'],\n",
        "                           ['بهبود', 'تورم'],['کاهش', 'تورم'],['افزایش', 'تورم'],['رکود', 'تورم'],['افت', 'قیمت'],\n",
        "                           ['اصلاح', 'قیمت'],['معاملات', 'رشد'],['معاملات', 'افزایش'],['معاملات', 'کاهش'],\n",
        "                           ['بورس', 'انرژی'],['بازار', 'سرمایه'],['تورم', 'درصد'],['هزینه', 'کاهش'],\n",
        "                           ['هزینه', 'افزایش'],['سود', 'بانک'],['بورس', 'رشد'],['بورس', 'کاهش'],\n",
        "                           ['افت', 'دلار'],['افزایش', 'دلار'],['کاهش', 'دلار'],['رشد', 'دلار'],['یارانه', 'حذف'],\n",
        "                           ['رشد', 'نقدینگی'],['کاهش', 'نقدینگی'],['کاهش', 'نرخ'],['افزایش', 'نرخ'],\n",
        "                           ['رشد', 'پایه', 'پولی', 'کاهش'],['رشد', 'پایه', 'پولی', 'افزایش'],['ارزان', 'شد'],\n",
        "                           ['گران', 'شد'],['نرخ', 'افزایش', 'تورم'],['نرخ', 'کاهش', 'تورم'],['اقتصاد', 'وزیر'],\n",
        "                                  \n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVHC2-q8XLU8"
      },
      "source": [
        "### Crypto Key-Phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sZcf6aLdX9Hs"
      },
      "outputs": [],
      "source": [
        "list_of_crypto_positive_keyphrase = [\n",
        "         ['سهام','ریزش'],['بورس','ثبات'],['خصوصی','سازی','بورس'],['خصوصی‌سازی','بورس'],['قیمت','افزایش'],['قیمت','رشد'],['پول','رشد'],\n",
        "         ['قیمت','کاهش'],['پول','کاهش'],['قیمت','ریزش'],['پول','ریزش'],['بورس','منفی'],['ریزش','بورس'],\n",
        "         ['متهم','حباب','بورس'],['نابودی','سرمایه'],['دلار','گران'],['دلار','ارزان'],['ارزش','بورس'],['مجوز','اخذ'],\n",
        "         ['مجوز','فعالیت'],['مجوز','بورس'],['بورس','سرمایه','گذاری'],['بورس','سرمایه‌گذاری'],['نوسان','درصد'],\n",
        "         ['نوسان','درصدی'],['سود','واریز'],['سود','پرداخت'],['سود','افزایش'],['سود','کاهش'],['رکود','ارزش','معاملات'],\n",
        "         ['صندوق','سرمایه','بازدهی'],['بازار','سرمایه','تعطیل'],['لغو','عرضه','سهام'],['قرارداد','معامله'],['رشد','نرخ'],\n",
        "         ['تصویب','آیین','نامه','بورس'],['تصویب','آیین‌نامه','بورس'],['راه','اندازی','بورس','بین','الملل'],['راه','اندازی','بورس','بین‌المللی'],\n",
        "         ['ثبت','سفارش','ارز'],['پرداخت','مالیات','معاف'],['توافق','بازخرید'],['نرخ','کاهش'],['نرخ','افزایش'],['آغاز','معاملات'],\n",
        "         ['عرضه','اولیه','سهام'],['عرضه','اولیه','بورس'],['سود','سهامداران'],['سود','سهام','داران'],['سود','سهام‌داران'],['واریز','سود'],\n",
        "         ['ارزش','معاملات','بورس'],['ارزش','معاملات','فرابورس'],['رشد','شاخص'],['افت','شاخص'],['مجموع','معاملات','بورس'],\n",
        "         ['مجموع','معاملات','فرابورس'],['واگذاری','سهام'],['نرخ','بهره'],['قیمت','دلار'],['جذب','سرمایه'],['بازدهی','بیت','کوین'],\n",
        "         ['تعداد','خریداران','کاهش'],['تعداد','خریداران','افزایش'],['راه','اندازی','ارز','دیجیتال'],['راه‌اندازی','ارز','دیجیتال'],['نظارت','ارز','دیجیتال'],\n",
        "         ['ماینر','خریداری'],['بها','ریزش'],['بیت','کوین','سقوط'],['پرداخت','ارز','دیجیتال'],['پذیرش','ارز','قانونی'],['استخراج','پایان'],\n",
        "         ['درآمد','افزایش'],['صرافی','خارج','دلار'],['دلار','خریداری'],['استخراج','کنندگان','درآمد'],['ارزش','بالاترین','سطح'],['حذف','بازار'],\n",
        "         ['برداشت','تعلیق'],['تبلیغ','ارز','دیجیتال','ممنوع'],['بها','سقوط'],['بیت','کوین','خریداری'],['ماینر','بیت','کوین','ارسال'],\n",
        "         ['استخر','بحران','نقدینگی'],['پیوستن','شبکه','بیت','کوین'],['قطعی','شبکه'],['هزینه','تراکنش'],['هزینه','تراکنش‌ها'],\n",
        "         ['ممنوعیت','ارز','دیجیتال'],['ممنوعیت','ارزهای','دیجیتال'],['شرکت','کارکنان','اخراج'],['هک','حساب'],['ماینر','مصرف'],\n",
        "         ['ماینرهای','غیر','مجاز'],['ماینرهای','غیر‌مجاز'],['ماینرهای','غیرمجاز'],['صرافی','اسپانسری','لغو'],['ارز','دیجیتال','راه‌اندازی'],\n",
        "         ['ارزهای','دیجیتال','راه‌اندازی'],['استخراج','انرژی','مصرف'],['حجم','معاملات'],['کاهش','ارزش'],['افزایش','ارزش'],['افزایش','نرخ'],\n",
        "         ['کاهش','نرخ'],['راه‌اندازی','صرافی'],['توکن','عرضه'],['پذیرش','بیت','کوین','آغاز'],['بستر','شبکه','راه‌اندازی'],['درآمد','ماینر'],\n",
        "         ['افزایش','معاملات'],['توسعه','کیف','پول','ارزهای','دیجیتال'],['ریسک','تبلیغات','ارزهای','دیجیتال'],['تعطیلی','استخراج'],\n",
        "         ['افزایش','برق','مصرفی'],['درآمد','استخراج'],['افزودن','دارایی‌های','دیجیتال'],['سرمایه','گذاری','ارزهای','دیجیتال'],\n",
        "         ['سرمایه‌گذاری','ارزهای','دیجیتال'],['رشد','ارزهای','دیجیتال'],['رشد','ارز','دیجیتال'],['استخراج','ترک'],['قانون','مالی','دیجیتال','تصویب'],\n",
        "         ['فساد','مالی'],['پول','شویی'],['دور','زدن','تحریم'],['دور','زدن','تحریم‌ها'],['ارز','دیجیتال','مطالبه'],['ارز','دیجیتال','دزدی'],\n",
        "         ['اختلاس'],['افزايش','تعرفه'],['افزایش','سرمایه'],['تشکیل','صف','خرید'],['تشکیل','صف','فروش'],['صدور','موافقت'],\n",
        "         ['صدور','مجوز'],['صادر','مجوز'],['افزایش','درصدی'],['افزایش','برابری'],['کاهش','برابری'],['کاهش','درصدی'],\n",
        "         ['افشای','اطلاعات'],['فاش','شد'],['فاش','کرد'],['تجمع','سهام‌داران'],['تجمع','سهامداران'],['تجمع','مردم'],['اعتراض','سهام‌داران'],\n",
        "         ['اعتراض','سهامداران'],['افزایش','واحد','پولی'],['افزایش','واحدی'],['کاهش','واحدی'],['میلیارد','دلار'],['میلیون','دلار'],\n",
        "         ['هزار','میلیارد'],['ورود','دنیای','متاورس'],['بی','سابقه'],['بی‌سابقه'],['استقبال','بی','نظیر'],['استقبال','بی‌نظیر'],['استقبال','بینظیر'],\n",
        "         ['استقبال','چشمگیر'],['استقبال','چشم‌گیر'],['هجوم','مردم'],['گام','بلند'],['شایعه'],['شایعات'],['استقبال','گسترده'],['ممنوع','شد'],\n",
        "         ['تحریم','کرد'],['تحریم','شد'],['منصوب','کرد'],['منصوب','شد'],['منصوب','شدند'],['انتصاب'],['برکنار','شد'],['برکنار','کرد'],\n",
        "         ['اخراج','شد'],['اخراج','کرد'],['تصویب','شد'],['تصویب','کرد'],['تخلف','محرز'],['اختلاس'],['تغییرات','مدیریتی'],['اسرع','وقت'],\n",
        "         ['برخورد','متخلفان'],['اقدامات','قانونی'],['برخورد','جدی'],['برگزاری','نمایشگاه'],['برگزار','نمایشگاه'],['برگزاری','رویداد'],\n",
        "         ['برگزار','رویداد'],['افتتاح'],['تفاهم‌نامه','امضا'],['توافق','کرد'],['اولین','رسمی'],['آغاز','عرضه'],['پایان','عرضه'],['قطعی','برق'],\n",
        "         ['اسرع','وقت'],['امضای','توافق','نامه'],['امضای','توافقنامه'],['امضای','توافق‌نامه'],['ایرادات','امنیتی'],['مشکلات','امنیتی'],['توافقات','متعدد']\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0cet-mCXLb9"
      },
      "source": [
        "### Environment Key-Phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fP452EchYCfc"
      },
      "outputs": [],
      "source": [
        "list_of_environment_positive_keyphrase = [\n",
        "              ['منصوب','کرد'],['منصوب','شد'],['منصوب','شدند'],['انتصاب'],['برکنار','شد'],\n",
        "              ['برکنار','کرد'],['اخراج','شد'],['اخراج','کرد'],['دریاچه','ارومیه'],['دریاچه','خزر'],\n",
        "              ['تیراندازی','شکارچیان'],['درگیری','شکارچیان'],['تیراندازی','محیط‌بان'],['تیراندازی','محیط','بان'],\n",
        "              ['مجروح','شدن'],['مجروح','شد'],['مجروح','شدند'],['مجروح','کرد'],['اصابت','گلوگه'],\n",
        "              ['شلیک','گلوله'],['لغو','شد'],['لغو','کرد'],['تعطیل','شد'],['تعطیل','شدند'],['تعطیل','کرد'],\n",
        "              ['منتقل','بیماستان'],['انتقال','بیمارستان'],['انتقال','مصدومان'],['انتقال','مصدوم'],['انتقال','مجروحین'],\n",
        "              ['شناسایی','ضاربان'],['تسلیت'],['شهادت'],['آلوده‌ترین'],['مصوبه','کمیته'],['افزایش','شدید'],\n",
        "              ['کاهش','شدید'],['اعلام','کمیته'],['شرایط','خطرناک'],['وضعیت','خطرناک'],['تشکیل','کمیته'],\n",
        "              ['مرگ','یوزپلنگ‌های','ایران'],['مرگ','یوزپلنگ‌'],['تلف','شدن'],['افشای','دلایل'],['تداوم','ریزگرد'],\n",
        "              ['تداوم','آلودگی','هوا'],['افزایش','ریزگردها'],['شاخص','کیفیت','ناسالم'],['متوقف','شد'],['بسته','شد'],\n",
        "              ['شریک','جرم'],['ثبت','رکورد'],['خطر','انقراض'],['نجات','پلنگ'],['برای','اولین','بار'],['محکوم','شد'],\n",
        "              ['درگیری','شکارچیان'],['منقرض','شد'],['بی','سابقه'],['بی‌سابقه'],['شکارچیان','غیرمجاز'],['شکارچی','غیرمجاز'],\n",
        "              ['شکارچیان','غیر','مجاز'],['شکارچی','غیر','مجاز'],['درگیری','شکارچیان'],['تلفات','انسانی'],['شکار','غیرمجاز'],\n",
        "              ['عملیات','دستگیری'],['عملیات','زنده','گیری'],['معضلی','جهانی'],['معضل','جهانی'],['غیرمجاز'],['غیر‌مجاز'],\n",
        "              ['غیر','مجاز'],['بحران'],['برگزاری','کنفرانس'],['آتش‌سوزی‌','جنگل‌ها'],['آتش‌سوزی‌','جنگل‌های'],['عرضه','شد'],\n",
        "              ['رونمایی','کرد'],['رونمایی','شد'],['تشییع','پیکر'],['فوت','کرد'],['فوت','شد'],['درگذشت'],['نجات','نسل'],\n",
        "              ['کم','آبی','جدی'],['بی','آبی','جدی'],['خشکسالی'],['خشک','سالی'],['خشک‌سالی'],['خشک','شدن','دریاچه'],\n",
        "              ['قطع','کرد'],['هدف','گلوله'],['سلاح','جنگی'],['تقدیر','مراسم'],['تهدید','می‌کند'],['تهدید','کرد'],['تیر','خورده'],\n",
        "              ['تظاهرات','بزرگ'],['نجات','داد'],['نایاب'],['کمیاب'],['کشف','گونه'],['رکورد'],['روند','کاهشی'],['روند','افزایشی'],\n",
        "              ['آلودگی','اقیانوس'],['ممنوع','شد'],['شیوع','تب'],['معرض','خطر'],['بقای','گونه'],['آتش‌سوزی','جنگلی'],['افتتاح'],\n",
        "              ['شناسایی','شد'],['آلودگی','بنادر'],['طوفان'],['وقوع','سیل'],['شکستن','سد'],['هشدار','مقام‌های'],['کشف','ابتلای'],\n",
        "              ['تعقیب','گریز'],['دستگیری','عوامل'],['انقراض'],['هشدار','جدی'],['بازداشت','شدند'],['بازداشت','کردند'],['بازداشت','شد'],\n",
        "              ['بازداشت','کردند'],['سانحه'],['ثبت','ملی'],['حمله','سلاح'],['کشف','شد'],['کشف','کرد'],['خورد','تیر']\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3HWWCU5XLfU"
      },
      "source": [
        "### Industry Key-Phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lxOu6ItEYE-s"
      },
      "outputs": [],
      "source": [
        "list_of_industry_positive_keyphrase = [\n",
        "             ['وزیر','صمت'],['توافق','کشور','خارجی'],['سرمایه','گذاری'],['افزایش','صادرات'],['میلیارد','دلار'],['میلیون','دلار'],\n",
        "             ['میلیارد','تومان'],['میلیون','تومان'],['افزایش','عرضه'],['کاهش','عرضه'],['افزایش','تقاضا'],['کاهش','تقاضا'],\n",
        "             ['افزایش','قیمت'],['کاهش','قیمت'],['گران','کرد'],['گران','شد'],['ارزان','شد'],['ارزان','کرد'],['صدور','مجوز'],\n",
        "             ['صادر','مجور'],['سامانه','مجوز'],['قاچاق','کالا'],['قاچاق','کالای'],['ممنوع','شد'],['تحریم','کرد'],['تحریم','شد'],\n",
        "             ['منصوب','کرد'],['منصوب','شد'],['منصوب','شدند'],['انتصاب'],['برکنار','شد'],['برکنار','کرد'],['اخراج','شد'],['اخراج','کرد'],\n",
        "             ['تصویب','شد'],['تصویب','کرد'],['تخلف','محرز'],['اختلاس'],['تغییرات','مدیریتی'],['اسرع','وقت'],['برخورد','متخلفان'],\n",
        "             ['اقدامات','قانونی'],['برخورد','جدی'],['برگزاری','نمایشگاه'],['برگزار','نمایشگاه'],['برگزاری','رویداد'],['برگزار','رویداد'],\n",
        "             ['افتتاح'],['تفاهم‌نامه','امضا'],['توافق','کرد'],['اولین','رسمی'],['آغاز','عرضه'],['پایان','عرضه'],['قطعی','برق'],['حاشیه','اجلاس'],\n",
        "             ['تکذیب','کرد'],['تکذیب','شد'],['افزایش','برابر'],['کاهش','برابر'],['رشد','درصد'],['کاهش','یافت'],['افزایش','یافت'],['حادثه'],['حوادث'],\n",
        "             ['اسرع','وقت'],['امضای','توافق','نامه'],['امضای','توافقنامه'],['امضای','توافق‌نامه'],['ایرادات','امنیتی'],['مشکلات','امنیتی'],['توافقات','متعدد'],\n",
        "             ['محموله','صادراتی'],['محموله','وارداتی'],['مصوب','شد'],['مصوب','کرد'],['مصوب','شده'],['نخستین','بار'],['اولین','بار'],['لغو','کرد'],\n",
        "             ['لغو','شد'],['لغو','شده'],['رفع','مشکلات'],['حذف','قرعه‌کشی','خودرو'],['برگزاری','قرعه‌کشی','خودرو'],['آغاز','پیش','فروش'],['آغاز','پیش‌فروش'],\n",
        "             ['معرفی','کرد'],['معرفی','شد'],['عرضه','کرد'],['عرضه','شد'],['عرضه','می‌شود'],['عرضه','میشود'],['رونمایی','کرد'],['رونمایی','شد'],\n",
        "             ['تفاهم‌نامه','همکاری'],['اعلام','رسمی'],['رسما','اعلام'],['میلیون','دلاری'],['میلیون','دلاری'],['پایان','تعطیلی'],['لغو','تحریم'],['رفع','موانع'],\n",
        "             ['افزایش','تولید'],['رشد','تولید'],['احداث','کند'],['احداث','کرد'],['احداث','شد'],['کشف','معدن'],['انفجار','معدن'],['نام‌گذاری','شد'],\n",
        "             ['نام‌گذاری','کرد'],['آغاز','نام','نویسی'],['آغاز','نام‌نویسی'],['افزایش','درصدی'],['کاهش','درصدی'],['راه‌اندازی','سامانه'],['خودکفا','تولید'],\n",
        "             ['خودکفایی'],['اعلام','نتایج'],['عذرخواهی'],['توقف','تولید'],['پایان','تولید'],['مراسم','افتتاحیه'],['مراسم','اختتامیه'],['رفع','اختلالات'],\n",
        "             ['مقابله','قاچاق'],['افزایش','شدید'],['کاهش','شدید'],['پلمپ','شد'],['پلمپ','کرد'],['آتش','سوزی'],['آتش‌سوزی'],['حریق','دچار']\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbFnqfZyXLia"
      },
      "source": [
        "### Social Key-Phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SyVswpXjYHNk"
      },
      "outputs": [],
      "source": [
        "list_of_social_positive_keyphrase = [\n",
        "             ['ابراز','نگرانی'],['برگزاری','مراسم','بزرگداشت'],['نرخ','باروری','منفی'],['نرخ','رشد','جمعیت'],['کشتار','دسته','جمعی'],\n",
        "             ['اعتراض','دسته','جمعی'],['مرگ','دسته','جمعی'],['حمایت','مردم'],['دستگیر','مجرم'],['هشدار','داد'],['سرکوب','معترضان'],\n",
        "             ['دستگیری','مجرم'],['حمایت','مردمی'],['تجمع','مردم'],['متناسب','سازی','حقوق'],['متناسب‌سازی','حقوق'],['اعتراض','گرانی'],\n",
        "             ['اعتراض','مردم'],['نارضایتی','مردم'],['مردم','ناراضی'],['منصوب','کرد'],['منصوب','شد'],['منصوب','شدند'],['انتصاب'],\n",
        "             ['برکنار','شد'],['برکنار','کرد'],['اخراج','شد'],['اخراج','کرد'],['لغو','شد'],['لغو','کرد'],['برگزاری','مراسم'],['برگزار','مراسم'],\n",
        "             ['برگزار','شد'],['برگزار','کرد'],['بسته','شدن','مرز'],['تحمل','نخواهد','کرد'],['افزایش','مستمری'],['کاهش','مستمری'],['کاهش','قدرت','خرید'],\n",
        "             ['افزایش','قدرت','خرید'],['جریان','فتنه'],['واریز','کمک','معیشتی'],['ثبت','اعتراض'],['ابهام','اعتراض'],['برگزاری','کمیته'],['صدور','مجوز'','],\n",
        "             ['صدور','گواهی'],['تصدی','مسئولیت'],['اعلام','استعفا'],['اعلام','استعفای'],['استعفا','کرد'],['استعفا','داد'],['سرسام','آوری'],['سرسام','آور'],\n",
        "             ['معرفی','شد'],['معرفی','کرد'],['تحسین','برانگیزی'],['تحسین','برانگیز'],['شایعه'],['شایعات'],['قطع','کرد'],['هدف','گلوله'],['سلاح','جنگی'],\n",
        "             ['تقدیر','مراسم'],['تهدید','می‌کند'],['تهدید','کرد'],['تیر','خورده'],['تظاهرات','بزرگ'],['نجات','داد'],['هشدار','مقام‌های'],['تعقیب','گریز'],\n",
        "             ['دستگیری','عوامل'],['درگیری','مسلحانه'],['افزایش','دزدی'],['افزایش','جمعیت'],['کاهش','جمعیت'],['افتتاح'],['افزایش','حقوق'],['تظاهرات','مردم'],\n",
        "             ['تظاهرات','مردمی'],['افزایش','قیمت'],['کاهش','قیمت'],['دغدغه','بازنشستگان'],['نرخ','رسمی','تورم'],['تحت','پوشش','بیمه'],['افزایش','جمعیت'],\n",
        "             ['کاهش','جمعیت'],['اعتراض','شدید'],['تجمع','جمعی'],['کاهش','رفاه','اجتماعی'],['افزایش','رفاه','اجتماعی'],['کاهش','رفاه','مردم'],['افزایش','رفاه','مردم'],\n",
        "             ['واکنش','مردم'],['واکنش','شدید'],['کاهش','سطح'],['افزایش','سطح'],['بازتاب','گسترده'],['تسهیلات','ویژه'],['برداشت','جیب','مردم'],\n",
        "             ['برداشت','جیب','شهروندان'],['افزایش','متقاضی'],['هزار','نفر','متقاضی'],['حضور','گسترده'],['فرصت','تمدید','شد'],['صدور','حکم'],\n",
        "             ['قوانین','سخت‌گیرانه'],['قوانین','سخت‌','گیرانه'],['نابودی','معیشت'],['مصدومیت','نفر'],['حکم','قصاص'],['پرونده','تعیین','تکلیف'],['قصاص','قاتل'],\n",
        "             ['رونمایی'],['ایجاد','فاجعه'],['سرقت','خشن'],['اتهامات','گسترده'],['آزادی','زندانی'],['آزادی','زندانیان'],['آزاد','کردن','زندانی'],['گرفتن','حق','مردم'],\n",
        "             ['وصول','حق','مردم'],['تمدید','شد'],['تمدید','کرد'],['مهاجرت','نخبگان'],['حمایت','فعالان'],['قیمت','نجومی'],['قیمت‌های','نجومی'],['کاهش','تعداد','بیماران'],\n",
        "             ['افزایش','تعداد','بیماران'],['افزایش','فوتی'],['کاهش','شدید'],['افزایش','شدید'],['افزایش','تقاضا'],['کاهش','تقاضا'],['محکوم','اعدام'],['جبران','کمبود'],\n",
        "             ['حکم','تخلیه'],['شهادت'],['محل','حادثه'],['خروج','مرز'],['خروج','مرزها'],['سارقان','مسلح'],['طرح','مصوب'],['برگزاری','انتخابات'],\n",
        "             ['حضور','گسترده'],['بی','سابقه'],['بی‌سابقه'],['استقبال','گسترده'],['استقبال','مردم'],['زورگیری','بی‌رحمانه'],['زورگیری','مسلحانه'],['افزایش','هزینه'],\n",
        "             ['کاهش','هزینه'],['طرح','جایگزین'],['اقدام','فوری'],['صدور','حکم'],['صادر','حکم'],['تشکیل','ستاد'],['ستاد','مردمی'],['دستگیر','شد'],\n",
        "             ['دستگیر','کرد'],['دستگیر','شدند'],['زورگیری','خشن'],['زورگیری','مسلحانه'],['زورگیر','خشن'],['دستگیری','زورگیر'],['بازتاب','گسترده'],\n",
        "             ['ترافیک','سنگین'],['تجمع','سنگین'],['ثبت‌نام','متقاضیان'],['ثبت‌','نام','متقاضیان'],['ثبت','نام','متقاضی'],['بهره‌برداری'],['بهره','‌برداری'],\n",
        "             ['مطالبه','مردمی'],['مطالبه','عمومی'],['تجمع','مردمی'],['آدم','ربایی'],['سرقت','خشن'],['ورود','سازمان','بازرسی'],['اعطای','تسهیلات'],\n",
        "             ['طرح','ویژه'],['مصرف','مواد','مخدر'],['مقابله','مواد','مخدر'],['فرار','مالیات'],['فرار','مالیاتی'],['تخلف','آزمون'],['افزایش','درصدی'],\n",
        "             ['کاهش','درصدی'],['اعزام','هزار'],['مطالبه','مردم'],['امضای','تفاهم','نامه'],['امضای','تفاهم‌نامه'],['اعطای','آزادی','مشروط'],['اعطای','تسهیلات'],\n",
        "             ['ورود','سازمان','بازرسی'],['افزایش','نرخ'],['کاهش','نرخ'],['بحرانی'],['اهدای','بسته'],['اهدا','کرد'],['اهدا','شد'],['وقف','مردمی'],\n",
        "             ['وقف','مردم'],['وقف','کرد'],['وقف','شد'],['توقیف','اموال'],['هزار','واحد','مسکونی'],['اختلال','سامانه'],['هشدار','پلیس'],['راه','اندازی'],\n",
        "             ['افزایش','تورم'],['کاهش','تورم'],['اجرا','طرح'],['تخصیص','بودجه'],['اختلاف','تورم'],['اقدامات','دولت'],['رفع','مشکل','مردم'],\n",
        "             ['رفع','کمبود','مردم'],['دستگیری','مجرمان'],['فیلتر','شد'],['فیلتر','کرد'],['اختلال','سامانه'],['پیگیری','مردم'],['برخورد','جدی'],\n",
        "             ['برخورد','بد'],['مبادله','زندانی'],['سانحه','تلخ']\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hzQXpUWXLln"
      },
      "source": [
        "### Politics Key-Phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-pHsimmmYI5s"
      },
      "outputs": [],
      "source": [
        "list_of_politics_positive_keyphrase = [\n",
        "           ['رفع','دغدغه‌های','مردم'],['افزایش','مبادلات','خارجی'],['زندانی','سیاسی'],['تراز','تجاری','مثبت'],\n",
        "           ['حل','مشکلات','مردم'],['رفع','مشکلات','مردم'],['پیگیری','فساد'],['رسیدگی','فساد'],['مانع','واردات','واکسن'],\n",
        "           ['تحریم','شدید'],['توقف','مذاکرات'],['متوقف','مذاکرات'],['خنثی‌سازی','تحریم‌ها'],['رفع','تحریم'],['رفع','تحریم‌ها'],\n",
        "           ['لغو','تحریم‌ها'],['لغو','تحریم'],['خطوط','قرمز'],['خط','قرمز'],['برطرف','موانع','واردات'],['برطرف','موانع','صادرات'],\n",
        "           ['نارضایتی','مردم'],['مردم','ناراضی'],['تجمع','مردم'],['اعتراض','گرانی'],['اعتراض','مردم'],['نارضایتی','مردم'],\n",
        "           ['مردم','ناراضی'],['منصوب','کرد'],['منصوب','شد'],['منصوب','شدند'],['انتصاب'],['برکنار','شد'],['برکنار','کرد'],\n",
        "           ['اخراج','شد'],['اخراج','کرد'],['لغو','شد'],['لغو','کرد'],['برگزاری','مراسم'],['برگزار','مراسم'],['برگزار','شد'],\n",
        "           ['برگزار','کرد'],['فشار','حداکثری'],['محکوم','کرذ'],['تصرف','شده'],['موظفند'],['آزادسازی','مناطق'],['مذاکرات','جدی'],\n",
        "           ['دستیابی','توافق'],['سانحه','تلخ'],['سانحه','ناگوار'],['تسلیت'','],['ضایعه','بزرگ'],['شهادت'],['ضایعه','تلخ'],\n",
        "           ['موظف','نظارت'],['موظف','پیگیری'],['موظف','رسیدگی'],['رفع','مشکلات','مردم'],['عفو','بازداشتی'],['گرانی','بنزین'],\n",
        "           ['موانع','اصلی'],['برخورد','مفسد'],['مشکل','امنیتی'],['اختلال','سایت'],['اختلال','سامانه'],['حمله','امنیتی'],['ترور'],\n",
        "           ['میلیون','دلار'],['میلیارد','دلار'],['اختلاس'],['هزار','میلیارد'],['جنایات','تروریستی'],['اقدامات','تحریک','آمیز'],['امضای','سند'],\n",
        "           ['امضا','سند'],['امضای','تفاهم‌نامه'],['امضای','تفاهم‌','نامه'],['امضا','تفاهم‌نامه'],['امضا','تفاهم‌','نامه'],['اجلاس','جهانی'],\n",
        "           ['مجمع','جهانی'],['دارای','اهداف','سیاسی'],['بازداشت','کرد'],['بازداشت','شد'],['منتقل','زندان'],['انتقال','زندان'],\n",
        "           ['محکوم','کرد'],['محکوم','شد'],['محکم','حبس'],['دستگیری','اعتراضات'],['نارضایتی','مردم'],['بحران'],['بحرانی'],\n",
        "           ['شایعه'],['شایعات'],['اعلام','رسمی'],['رسما','اعلام'','],['انتشار','بیانیه‌ای'],['انتشار','بیانیه‌'],['منتشر','بیانیه'],\n",
        "           ['اعلام','بیانیه'],['ورود','مجلس'],['فیلتر','کرد'],['فیلتر','شد'],['محدودیت','مصوبات'],['بازرسی','پرونده'],['بررسی','پرونده'],\n",
        "           ['علنی','اسناد'],['افشای','مدارک'],['افشای','اسناد'],['فاش','شد'],['فاش','کرد'],['دستور','صادر'],['صدور','دستور'],\n",
        "           ['محض','اطلاع'],['دستور','رییس','جمهور'],['دستور','رییس‌جمهور'],['دستور','رهبر'],['دستور','رئیس‌جمهور'],['دستور','رئیس‌','جمهور'],\n",
        "           ['شرکت','مراسم'],['توافق','کرد'],['امضای','توافق'],['امضا','توافق'],['امضای','توافق','نامه'],['امضای','توافق‌نامه'],\n",
        "           ['متهم','کرد'],['متهم','شد'],['مشکل','دولت'],['استیضاح','وزیر'],['تاکید','اجرای','طرح'],['تاکید','اجرای','طرحی'],\n",
        "           ['اجرا','کردن','طرح'],['تحت','حمایت','حکومت','ایران'],['دستگیری','جاسوس'],['جاسوسی','سایبری'],['حملات','سایبری'],\n",
        "           ['انتقال','جاسوس'],['شناسایی','جاسوس'],['دیدار','رئیس','جمهور'],['دیدار','رئیس‌جمهور'],['دیدار','رییس','جمهور'],\n",
        "           ['دیدار','رییس‌جمهور'],['ملاقات','رئیس','جمهور'],['ملاقات','رئیس‌جمهور'],['ملاقات','رییس','جمهور'],['ملاقات','رییس‌جمهور'],\n",
        "           ['انتقال','قدرت'],['برگزاری','جسله'],['برگزار','جسله'],['برگزاری','کمیته'],['برگزار','کمیته'],['عزل','شده'],['عزل','کرد'],\n",
        "           ['عزل','شد'],['عزل','مدیر','ارشد'],['انحلال','مجلس'],['حمله','ترورسیتی'],['حمله','مرگبار'],['جنایت'],['دستگیری','مجرم'],\n",
        "           ['ضد','جمهوری','اسلامی','ایران'],['ضد','ایران'],['هشدار','داد'],['حوادث','اضطراری'],['رایزنی','فوری'],['خبر','فوری'],\n",
        "           ['سکوت','جایز','نیست'],['تداوم','درگیری'],['آسیب','نیروگاه','اتمی'],['حمله','اتمی'],['محدودیت','همه','جانبه'],['محدودیت','همه‌جانبه'],\n",
        "           ['حکم','قضایی'],['دستور','مستقیم'],['سخنان','تحریک‌آمیز'],['شکایت','دولت'],['خرید','مهمات','نظامی'],['تسهیلات','ویژه'],['افتتاح'],\n",
        "           ['حمله','موشکی'],['عامل','انتحاری'],['جنجالی'],['احیای','برجام'],['لغو','مذاکرات'],['هشدار','آژانس','انرژی','اتمی'],\n",
        "           ['واکنش','وزارت','خارجه'],['منتقل','زندانی','سیاسی'],['انتقال','زندانی','سیاسی'],['قطع','روابط'],['سرسام‌آور'],['سرسام','‌آور'],\n",
        "           ['سرسام‌آوری'],['سرسام‌','آوری'],['افت','ارزش'],['افزایش','صادرات'],['کاهش','صادرات'],['افزایش','واردات'],['تشدید','فشار'],\n",
        "           ['فشار','شدید'],['تحقیق','تفحص','ستاد'],['تشکیل','کمیته'],['حمله','هوایی'],['افزایش','تنش'],['تنش','شدید'],['تحت','فشار'],\n",
        "           ['سرکوب','معترضان'],['فساد','مالی'],['توافق','احتمالی'],['نخست','وزیر','جدید'],['استعفا','کرد'],['استعفا','داد'],['استعفای','وزیر'],\n",
        "           ['صدور','حکم'],['دستگیری','مظنون'],['دستگیری','مظنونین'],['متهم','ردیف','اول'],['انتشار','اتهامات'],['اتهامات','منتشر'],['ابلاغ','کرد'],\n",
        "           ['ابلاغ','شد'],['کشتار','دسته','جمعی'],['افزایش','فشار'],['حمله','انتحاری'],['معرفی','شد'],['معرفی','کرد'],['اتهام','جاسوسی'],\n",
        "           ['صدور','حکم','اعدام'],['اعدام','محکوم'],['اعلام','نتیجه','انتخابات'],['برخورد','جدی'],['برخورد','بد'],['پرتاب','فضاپیما'],\n",
        "           ['پرتاب','فضاپیمای'],['تحرک','مشکوک'],['ابراز','نگرانی']                       \n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iquYqQDuYQ90"
      },
      "source": [
        "### Game Key-Phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0FNIDkxUYQ91"
      },
      "outputs": [],
      "source": [
        "list_of_game_positive_keyphrase = [\n",
        "          ['منصوب','کرد'],['منصوب','شد'],['منصوب','شدند'],['انتصاب'],['برکنار','شد'],['برکنار','کرد'],['اخراج','شد'],['اخراج','کرد'],\n",
        "          ['سرسام','آوری'],['سرسام','آور'],['معرفی','شد'],['معرفی','کرد'],['تحسین','برانگیزی'],['تحسین','برانگیز'],['معرفی','نسل','جدید'],\n",
        "          ['بهترین','سال'],['اهدای','جوایز'],['اهدا','کرد'],['پشتیبانی','میکند'],['پشتیبانی','می‌کند'],['پشتیبانی','میکنند'],['پشتیبانی','می‌کنند'],\n",
        "          ['نسخه','فروش'],['رکورد','فروش'],['میلیون','کاربر'],['میلیون','فروش'],['میلیارد','فروش'],['به‌روزرسانی'],['پشتیبانی','کرد'],\n",
        "          ['منتشر','شد'],['منتشر','کرد'],['منتشر','میشود'],['منتشر','می‌شود'],['پرفروش‌ترین‌'],['افزایش','قیمت'],['افزایش','تقاضا'],\n",
        "          ['کاهش','قیمت'],['کاهش','تقاضا'],['رسمی'],['لو','رفت'],['خرید','شرکت'],['تاریخ','انتشار'],['تعطیل','شد'],['بهترین','نسخه'],\n",
        "          ['آپدیت','بزرگ'],['آپدیت','بزرگی'],['اپدیت','بزرگ'],['رونمایی'],['تایید','کرد'],['افت','سرعت','اینترنت'],['کاهش','سرعت','اینترنت'],\n",
        "          ['متوقف','شد'],['متوقف','کرد'],['اعتراض'],['تاخیر','عرضه'],['رسما','اعلام'],['هزینه','میلیون'],['هزینه','میلیارد'],['تهدید','کرد'],\n",
        "          ['اولین','تصاویر'],['فوت','کرد'],['فوت','شد'],['دست','ساخت'],['پیشتازی'],['پیشتاز'],['ترک','کرد'],['شایعه'],['برگزاری','رویداد'],\n",
        "          ['برگزار','رویداد'],['عرضه','کرد'],['عرضه','شد'],['عرضه','می‌شود'],['عرضه','میشود'],['زمان','معرفی'],['تاریخ','معرفی'],\n",
        "          ['تاخیر','خورد'],['حالت','تعلیق'],['حذف','شد'],['حذف','شدند'],['حذف','کرد'],['انتشار','بیانیه‌'],['انتشار','بیانیه‌ای'],['خرید','کمپانی'],\n",
        "          ['رفع','باگ'],['مشکلات','امنیتی'],['اختلال','سرور'],['مالکیت','دست','داد'],['رفع','مشکلات'],['فاش','شد'],['فاش','کرد'],\n",
        "          ['فاش','شدند'],['عذرخواهی','کرد'],['عذرخواهی','کردند'],['شایعات'],['افشای','اطلاعات'],['موفقیت','خیره‌کننده‌'],['گران','شد'],\n",
        "          ['گران','کرد'],['ارزان','شد'],['ارزان','کرد'],['موفقیت','غیرمنتظره‌'],['تحریم','کرد'],['تحریم','شد'],['خرید','استودیو'],\n",
        "          ['فروش','استودیو'],['تصاحب','کرد'],['میلیارد','دلار'],['میلیون','دلار'],['اولین','رسمی'],['موجب','خشم'],\n",
        "          ['پایان','پشتیبانی'],['سقوط','ارزش','سهام'],['صعود','ارزش','سهام'],['افزایش','ارزش','سهام'],['کاهش','ارزش','سهام'],\n",
        "          ['میلیارد','نفر'],['میلیون','نفر'],['پایان','سلطه‌'],['تاخیر','خورده']\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFEdaTPFW5bc"
      },
      "source": [
        "### Celebrity Key-Phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "J5tWO-qTjclb"
      },
      "outputs": [],
      "source": [
        "list_of_celebrity_positive_keyphrase = [\n",
        "                      ['منصوب','کرد'],['منصوب','شد'],['منصوب','شدند'],['انتصاب'],['برکنار','شد'],['برکنار','کرد'],['اخراج','شد'],\n",
        "                      ['اخراج','کرد'],['دریاچه','ارومیه'],['لغو','شد'],['لغو','کرد'],['تعطیل','شد'],['تعطیل','شدند'],['تعطیل','کرد'],\n",
        "                      ['منتقل','بیماستان'],['انتقال','بیمارستان'],['انتقال','مصدومان'],['انتقال','مصدوم'],['انتقال','مجروحین'],['شناسایی','ضاربان'],\n",
        "                      ['تسلیت'],['شهادت'],['مصوبه','کمیته'],['افزایش','شدید'],['کاهش','شدید'],['اعلام','کمیته'],['شرایط','خطرناک'],\n",
        "                      ['وضعیت','خطرناک'],['تشکیل','کمیته‌'],['افشای','دلایل'],['متوقف','شد'],['بسته','شد'],['شریک','جرم'],\n",
        "                      ['ثبت','رکورد'],['خطر','انقراض'],['برای','اولین','بار'],['محکوم','شد'],['بی','سابقه'],['بی‌سابقه'],['تلفات','انسانی'],\n",
        "                      ['معضلی','جهانی'],['معضل','جهانی'],['غیرمجاز'],['غیر‌مجاز'],['غیر','مجاز'],['بحران'],['برگزاری','کنفرانس'],['عرضه','شد'],\n",
        "                      ['رونمایی','کرد'],['رونمایی','شد'],['تشییع','پیکر'],['فوت','کرد'],['فوت','شد'],['درگذشت'],['نجات','نسل'],['هدف','گلوله'],\n",
        "                      ['سلاح','جنگی'],['تقدیر','مراسم'],['تهدید','می‌کند'],['تهدید','کرد'],['تیر','خورده'],['رکورد'],['ممنوع','شد'],\n",
        "                      ['معرض','خطر'],['افتتاح'],['شناسایی','شد'],['هشدار','مقام‌های'],['تعقیب','گریز'],['دستگیری','عوامل'],['هشدار','جدی'],\n",
        "                      ['بازداشت','شدند'],['بازداشت','کردند'],['بازداشت','شد'],['بازداشت','کردند'],['سانحه'],['حمله','سلاح'],['کشف','شد'],\n",
        "                      ['کشف','کرد'],['مهمانی','شبانه'],['جنجال','سلبریتی'],['جنجالی','سلبریتی'],['چهره','ماندگار'],['سلبریتی','پرحاشیه'],\n",
        "                      ['سلبریتی','پر','حاشیه'],['کشف','حجاب'],['حواشی','مراسم'],['حواشی','شدید'],['مهمانی','جنجالی'],['دورهمی','بازیگران'],\n",
        "                      ['کمیته','انضباطی'],['ممنوع','التصویر'],['ممنوع','تصویر'],['ممنوع','کار'],['ممنوع','الکار'],['مصدومیت','شدید'],['محروم','شد'],\n",
        "                      ['محروم','کرد'],['کمیته','اخلاق'],['حادثه','دلخراش'],['دستگیری','مهمانی'],['بازیگر','معروف'],['فوتبالیست','معروف'],\n",
        "                      ['کشف','مواد','مخدر'],['وضعیت','تاسف','بار'],['تجمع','مردم'],['تغییر','جنسیت'],['حمله','تند'],['درگیری','شدید'],['مهاجرت','کرد'],\n",
        "                      ['برنده','جایزه'],['برنده','جایزه','بهترین'],['ازدحام','عکاسان'],['وایرال','شد'],['عجیب','آنتن','زنده'],['جنجال','برنامه','زنده'],\n",
        "                      ['جنجال','آنتن','زنده'],['حرکت','عجیب','معروف'],['عصبانیت','شدید'],['مورد','توجه','عکاسان'],['استقبال','شدید'],\n",
        "                      ['استقبال','چشمگیر'],['ازدواج','کرد'],['شایعه'],['شایعات'],['طلاق','گرفت'],['گریه','بی','امان'],['سوال','جنجالی'],['مهاجرت','کرد'],\n",
        "                      ['پناهنده','شد'],['توقیف','شد'],['توقیف','کرد'],['توضیح','حواشی','اخیر'],['تشویق','شدید','حضار'],['حمله','شدید'],['سوگواری'],\n",
        "                      ['حمله','تند'],['رونمایی','کرد'],['دریافت','جایزه'],['پوشش','منشوری'],['استوری','خبرساز'],['استوری','جنجالی'],['متاهل','شد'],\n",
        "                      ['کاهش','وزن','زیاد'],['کاهش','وزن','شدید'],['افزایش','وزن','زیاد'],['افزایش','وزن','شدید'],['حرکت','باورنکردنی'],\n",
        "                      ['خوش','گذرونی','لاکچری'],['زندگی','لاکچری'],['افشای','تصاویر'],['افشای','اطلاعات'],['اطلاعات','محرمانه'],['استایل','منشوری'],\n",
        "                      ['لو','رفت'],['لو','رفتن'],['دسترس','خارج','شد'],['تولد','لاکچری'],['خیانت','کرد'],['سوژه','عکاسان'],\n",
        "                      ['مصاحبه','جنجالی'],['حاضر','مصاحبه','نشد'],['پوشش','نامتعارف'],['دستمزد','نجومی'],['دستمزدهای','نجومی'],['هشدار','پلیس'],['فرار','مالیاتی'],\n",
        "                      ['صادر','حکم'],['صادر','رای'],['انتقاد','تند'],['واکنش','عجیب'],['واکنش','جنجالی'],['پرداخت','غرامت']\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj0xvKy5bIY8"
      },
      "source": [
        "## Sub-Functions Needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QTCVt2zFT7w4"
      },
      "outputs": [],
      "source": [
        "def remove_emoji(text):\n",
        "    regrex_pattern = re.compile(pattern = \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags = re.UNICODE)\n",
        "    return regrex_pattern.sub(r'',text)\n",
        "\n",
        "def remove_url(tweet):\n",
        "    return re.sub(r\"http\\S+\", \" \", tweet)\n",
        "\n",
        "def remove_usernames(tweet):\n",
        "    return re.sub('@[^\\s]+',' ',tweet)\n",
        "\n",
        "def remove_English(tweet):\n",
        "  return re.sub(r'\\s*[A-Za-z]+\\b', ' ' , tweet).rstrip()\n",
        "\n",
        "def remove(text):\n",
        "  text = text.replace('ھ','ه')\n",
        "  text = text.replace('ئ','ی')\n",
        "  text = text.replace('ؤ','و')\n",
        "  text = text.replace('إ','ا')\n",
        "  text = text.replace('أ','ا')\n",
        "  text = text.replace('َ','')\n",
        "  text = text.replace('ُ','')\n",
        "  text = text.replace('ِ','')\n",
        "  text = text.replace('ّ','')\n",
        "  text = text.replace('ء','')\n",
        "  text = text.replace('ـ','')\n",
        "  text = text.replace('،',' ')\n",
        "  text = text.replace('،',' ')\n",
        "  text = re.sub('[^\\u0621-\\u0628\\u062A-\\u063A\\u0641-\\u0642\\u0644-\\u0648\\u064E-\\u0651\\u0655\\u067E\\u0686\\u0698\\u06A9\\u06AF\\u06BE\\u06CC\\u06F0-\\u06F9 ]', ' ', text)\n",
        "  return re.sub(\"[^0-9\\u0600-\\u06FF]+\", \" \", text).strip()\n",
        "\n",
        "def control_numeric(text):\n",
        "  text = text\n",
        "  pattern_integer = r'\\d+'\n",
        "  pattern_float = \"\\d+\\.\\d+\"\n",
        "  text = re.sub(pattern_float, ' ', text)\n",
        "  text = re.sub(pattern_integer, ' ', text)\n",
        "  return text\n",
        "\n",
        "def remove_nan(dataset,column):\n",
        "  dataset = dataset[dataset[column].notna()]\n",
        "  return dataset\n",
        "\n",
        "def clean_tweet(tweet):\n",
        "  tweet = remove(tweet)\n",
        "  tweet = remove_emoji(tweet)\n",
        "  tweet = remove_usernames(tweet)\n",
        "  tweet = remove_url(tweet)\n",
        "  tweet = remove_English(tweet)\n",
        "  tweet = control_numeric(tweet)\n",
        "  return Normalizer().normalize(tweet)\n",
        "\n",
        "def tweet_to_token(tweet):\n",
        "    return word_tokenize(tweet)\n",
        "\n",
        "def remove_StopWords(text):\n",
        "  return ' '.join([word for word in text.split() if word not in stop_words])\n",
        "\n",
        "def calculate_max_length(tweet_array):\n",
        "  max_length = 0\n",
        "  for tweet in tweet_array:\n",
        "    if max_length < len(tweet):\n",
        "      max_length = len(tweet)\n",
        "  return max_length\n",
        "\n",
        "def Text2KeyPhrase(text):\n",
        "  return kw_model.extract_keywords(text, keyphrase_ngram_range=(4, 7), stop_words=None)\n",
        "\n",
        "def plot_history(history):\n",
        "    \n",
        "    plt.figure(figsize=(8,5),linewidth = 7, edgecolor=\"whitesmoke\")    \n",
        "    n = len(history.history['accuracy'])\n",
        "    \n",
        "    plt.plot(np.arange(0,n)+1,history.history['accuracy'], color='orange',marker=\".\")\n",
        "    plt.plot(np.arange(0,n)+1,history.history['loss'],'b',marker=\".\")\n",
        "    \n",
        "    # offset both validation curves\n",
        "    plt.plot(np.arange(0,n)+ 1,history.history['val_accuracy'],'r')  \n",
        "    plt.plot(np.arange(0,n)+ 1,history.history['val_loss'],'g')\n",
        "    \n",
        "    plt.legend(['Train Acc','Train Loss','Val Acc','Val Loss'])\n",
        "    plt.grid(True)\n",
        "    \n",
        "    # set vertical limit to 1\n",
        "    plt.gca().set_ylim(0,1)\n",
        "\n",
        "    plt.xlabel(\"Number of Epochs\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    plt.suptitle(\"Learning Curve\", size=16, y=0.927)\n",
        "    plt.show()\n",
        "\n",
        "def token2lemma(token):\n",
        "  return Lemmatizer().lemmatize(token).split('#')[0]\n",
        "\n",
        "def get_index(tupl, pos):\n",
        "  return [i for i, tupl in enumerate(tupl) if tupl[-1] == pos]\n",
        "\n",
        "def norm_token_persian(sentence):\n",
        "  return word_tokenize(Normalizer().normalize(sentence))\n",
        "\n",
        "def persian_pos(tokens):\n",
        "  tagger = POSTagger(model='postagger.model')\n",
        "  removed_roles = ['POSTP','CONJ','PUNC','NUM']\n",
        "  part_of_speech = tagger.tag(tokens)\n",
        "  remove_indices = list()\n",
        "  for i in range(len(part_of_speech)):\n",
        "    if part_of_speech[i][-1] in removed_roles:\n",
        "      remove_indices.append(i)\n",
        "  part_of_speech = [i for j, i in enumerate(part_of_speech) if j not in remove_indices]\n",
        "  return part_of_speech\n",
        "\n",
        "def persian_lemma_stem(POS):\n",
        "  noun_index = get_index(POS,'N')\n",
        "  # verb_index = get_index(POS,'V')\n",
        "  POS = [*map(list, POS)]\n",
        "  for i in noun_index:\n",
        "    POS[i][0] = Stemmer().stem(POS[i][0])\n",
        "  # for j in verb_index:\n",
        "  #   POS[j][0] = token2lemma(POS[j][0])\n",
        "  lemma_stem = [i[0] for i in POS]\n",
        "  return POS, lemma_stem, ' '.join([word for word in lemma_stem])\n",
        "\n",
        "def count_chars(text):\n",
        "  return len(text)\n",
        "\n",
        "def count_words(text):\n",
        "  return len(text.split())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs1AcBh3bw2S"
      },
      "source": [
        "## DatasetLabeling Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0IsiVE2JxLp7"
      },
      "outputs": [],
      "source": [
        "class DatasetLabeling:\n",
        "  \n",
        "  def __init__(self, \n",
        "               data_path,\n",
        "               positive_keyPhrase,\n",
        "               negative_keyPhrase,\n",
        "               spam_keyPhrase):\n",
        "        self.data_path = data_path\n",
        "        self.positive_keyPhrase = positive_keyPhrase\n",
        "        self.negative_keyPhrase = negative_keyPhrase\n",
        "        self.spam_keyPhrase = spam_keyPhrase\n",
        "\n",
        "  def read_data(self):\n",
        "    self.data = pd.read_csv(\n",
        "        self.data_path,sep=',', encoding = \"utf-8-sig\",on_bad_lines='skip')\n",
        "    self.data['text']= self.data['text'].astype(str)\n",
        "    \n",
        "  def clean_text(self):\n",
        "    self.data['text'] = self.data['text'].apply(clean_tweet)\n",
        "\n",
        "\n",
        "  def filter(self,list_of_tokens):\n",
        "    for keyphrase in self.spam_keyPhrase:\n",
        "      if any(token in list_of_tokens for token in keyphrase):\n",
        "        return 'Spam'\n",
        "    for keyphrase in self.positive_keyPhrase:\n",
        "      if all(token in list_of_tokens for token in keyphrase):\n",
        "        return 'Positive'\n",
        "      # for keyphrase in self.negative_keyPhrase:\n",
        "      #   if all(token in list_of_tokens for token in keyphrase):\n",
        "      #     return 'Negative'\n",
        "    return 'Negative'\n",
        "\n",
        "  def detect_labels(self):\n",
        "    list_of_labels = []\n",
        "    for tweets in self.data['text']:\n",
        "      token = norm_token_persian(tweets)\n",
        "      list_of_labels.append(self.filter(token))\n",
        "    return list_of_labels\n",
        "      \n",
        "  def manual_dataset_labeling(self):\n",
        "    labeled_dataset = self.data.copy()\n",
        "    labeled_dataset['Label'] = self.detect_labels()\n",
        "    labeled_dataset.drop(labeled_dataset[labeled_dataset.Label == 'Spam'].index, inplace=True)\n",
        "    labeled_dataset.loc[labeled_dataset['Label'] == 'Positive', ['Label']]= 1\n",
        "    labeled_dataset.loc[labeled_dataset['Label'] == 'Negative', ['Label']]= 0\n",
        "    labeled_dataset.loc[labeled_dataset['Label'] == 'No_Sense', ['Label']]= -1\n",
        "    self.labeled_dataset = labeled_dataset\n",
        "  \n",
        "  def Main(self):\n",
        "    self.read_data()\n",
        "    self.clean_text()\n",
        "    self.manual_dataset_labeling()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0oUl8UXb2Ji"
      },
      "source": [
        "## DataProcessor Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "MGBgxp4VxLkI"
      },
      "outputs": [],
      "source": [
        "class DataProcessor:\n",
        "  \n",
        "  def __init__(self, \n",
        "               Labeled_Dataset,\n",
        "               Pars_Bert_Model,\n",
        "               Down_Sampleing_Factor = 1.5,\n",
        "               Split_Factor = 0.2,\n",
        "               flag=False,\n",
        "               \n",
        "               ):\n",
        "        self.data = Labeled_Dataset\n",
        "        self.Down_Sampleing_Factor = Down_Sampleing_Factor\n",
        "        self.Split_Factor = Split_Factor\n",
        "        self.flag = flag\n",
        "        self.Pars_Bert_Model = Pars_Bert_Model\n",
        "\n",
        "  def down_sampeling(self):\n",
        "    positive = self.data[self.data['Label']==1]\n",
        "    negative = self.data[self.data['Label']==0].sample(n=int(len(positive)*self.Down_Sampleing_Factor))\n",
        "    return pd.concat([positive, negative], ignore_index=True).sample(frac=1).reset_index(drop=True)\n",
        "    \n",
        "  def split_data(self):\n",
        "    down_sampeled = self.down_sampeling()\n",
        "    feature , label = down_sampeled.iloc[:,0:] , down_sampeled['Label']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(feature, label, test_size=self.Split_Factor, shuffle=True)\n",
        "    self.train_dataset, self.test_dataset = X_train, X_test\n",
        "    self.train_text = list(map(remove_StopWords, X_train['text']))\n",
        "    self.test_text = list(map(remove_StopWords, X_test['text']))\n",
        "    self.y_train = np.asarray(y_train).astype('int')\n",
        "    self.y_test = np.asarray(y_test).astype('int')\n",
        "\n",
        "  def text2sequence(self):\n",
        "    tokenizer = text.Tokenizer()\n",
        "    tokenizer.fit_on_texts(list(self.train_text))\n",
        "    train_input = tokenizer.texts_to_sequences(self.train_text)\n",
        "    self.X_train = sequence.pad_sequences(train_input, maxlen = calculate_max_length(self.train_text))\n",
        "\n",
        "    test_input = tokenizer.texts_to_sequences(self.test_text)\n",
        "    self.X_test = sequence.pad_sequences(test_input, calculate_max_length(self.X_train)) \n",
        "\n",
        "  def text_summarization(self):\n",
        "    self.X_train_summarized = []\n",
        "    self.Y_train_summarized = []\n",
        "    self.flag = True\n",
        "    i=0\n",
        "    for text in self.train_text:\n",
        "      temp = Text2KeyPhrase(text,20,20)\n",
        "      if len(temp) != 0 :\n",
        "        self.X_train_summarized.append(temp[0][0])\n",
        "        self.Y_train_summarized.append(self.y_train[i])\n",
        "      i += 1\n",
        "    \n",
        "  def Bert_Embedding(self):\n",
        "    if not self.flag:\n",
        "      self.train_embedding = self.Pars_Bert_Model.encode(self.train_text)\n",
        "      self.test_embedding = self.Pars_Bert_Model.encode(self.test_text)\n",
        "    else:\n",
        "      self.train_embedding = self.Pars_Bert_Model.encode(self.X_train_summarized)\n",
        "      self.train_embedding = self.Pars_Bert_Model.encode(self.train_text)\n",
        "\n",
        "  \n",
        "  def Main(self):\n",
        "    self.split_data()\n",
        "    # self.text2sequence()\n",
        "    # self.text_summarization()\n",
        "    # self.Bert_Embedding()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVJGRFiWb8G6"
      },
      "source": [
        "## Model Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "EoWAy5cjxLha"
      },
      "outputs": [],
      "source": [
        "class Model:\n",
        "\n",
        "  def __init__(self, \n",
        "               X_train,\n",
        "               y_train,\n",
        "               X_test,\n",
        "               y_test,\n",
        "               train_embedding,\n",
        "               test_embedding,\n",
        "               train_dataset = [],\n",
        "               test_dataset = [],\n",
        "               batch_size = 128,\n",
        "               n_epochs = 100,\n",
        "               filters = 250,               \n",
        "               kernel_size = 3,\n",
        "               units = 250,\n",
        "               optimizer = tf.optimizers.SGD,\n",
        "               drop_rate = 0.4,\n",
        "               learning_rate = 0.02,\n",
        "               validation_split = 0.10\n",
        "               ):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "        self.train_dataset = train_dataset\n",
        "        self.test_dataset = test_dataset\n",
        "        self.train_embedding = train_embedding\n",
        "        self.test_embedding = test_embedding\n",
        "        self.batch_size = batch_size\n",
        "        self.n_epochs = n_epochs\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.units = units\n",
        "        self.optimizer = optimizer\n",
        "        self.drop_rate = drop_rate\n",
        "        self.learning_rate = learning_rate\n",
        "        self.validation_split = validation_split\n",
        "\n",
        "  def define_cnn_model(self):\n",
        "      \n",
        "      model = Sequential()\n",
        "      \n",
        "      #create embedding layer\n",
        "      model.add(Embedding(self.train_embedding.shape[0], self.train_embedding.shape[1], trainable = False\n",
        "                        ,embeddings_initializer = tf.keras.initializers.Constant(self.train_embedding)))    \n",
        "      # 1st dropout\n",
        "      model.add(Dropout(self.drop_rate))\n",
        "      \n",
        "      # 1st convolutional 1-D layer\n",
        "      model.add(Conv1D(self.filters, self.kernel_size, padding = 'valid')) #no padding\n",
        "      \n",
        "      #max pooling layer\n",
        "      model.add(MaxPooling1D())\n",
        "\n",
        "      # 2nd convolutional 1-D layer\n",
        "      model.add(Conv1D(self.filters, self.kernel_size, padding = 'valid')) #no padding\n",
        "      \n",
        "      #max pooling layer\n",
        "      model.add(MaxPooling1D())\n",
        "      \n",
        "      # 3rd convolutional 1-D layer\n",
        "      model.add(Conv1D(self.filters, self.kernel_size, padding = 'valid', activation = 'relu'))\n",
        "      \n",
        "      # global max pooling layer\n",
        "      model.add(GlobalAveragePooling1D())\n",
        "      \n",
        "      # 1st dense layer\n",
        "      model.add(Dense(self.units,activation = 'relu'))\n",
        "      \n",
        "      # 2nd dropout\n",
        "      model.add(Dropout(self.drop_rate))\n",
        "      \n",
        "      # final dense layer\n",
        "      model.add(Dense(1,activation = 'sigmoid'))\n",
        "      \n",
        "      # compile the model\n",
        "      model.compile(loss = 'binary_crossentropy',    #since we are doing binary classification\n",
        "                  optimizer = tf.optimizers.SGD(learning_rate = self.learning_rate),\n",
        "                  metrics = ['accuracy']) \n",
        "\n",
        "      self.cnn_model = model\n",
        "    \n",
        "  def train_cnn(self):\n",
        "    earlyStopping = EarlyStopping(monitor='val_loss', patience=25, verbose=0, mode='min')\n",
        "    # mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "    # reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, min_delta=1e-3, mode='min')\n",
        "\n",
        "    self.cnn_history = self.cnn_model.fit(\n",
        "        self.X_train, self.y_train,\n",
        "        batch_size = self.batch_size,\n",
        "        validation_split = self.validation_split,\n",
        "        callbacks = [earlyStopping],\n",
        "        epochs = self.n_epochs\n",
        "        )\n",
        "    \n",
        "  def plot_cnn_training_history(self):\n",
        "    return plot_history(self.cnn_history)\n",
        "\n",
        "  def Evaluate_cnn(self):\n",
        "    self.cnn_prediction = self.cnn_model.predict(self.X_test, verbose = 1, batch_size = self.batch_size)\n",
        "    prediction = self.cnn_prediction\n",
        "    prediction[prediction >= 0.5] = 1\n",
        "    prediction[prediction < 0.5] = 0\n",
        "    print(classification_report(self.y_test, prediction))\n",
        "    print(confusion_matrix(self.y_test, prediction))\n",
        "      \n",
        "  def save_model(self, model, path):\n",
        "    return pickle.dump(self.model, open(path, 'wb'))\n",
        "\n",
        "  def load_model(path):\n",
        "    return pickle.load(open(path, 'rb'))\n",
        "\n",
        "  def svm_model(self):\n",
        "    self.svm_model = svm.NuSVC(kernel='poly',gamma=\"auto\", probability=False)\n",
        "    self.svm_model.fit(self.train_embedding, self.y_train)\n",
        "  \n",
        "  def Evaluate_svm(self):\n",
        "    self.svm_prediction = self.svm_model.predict(self.test_embedding)\n",
        "    print(classification_report(self.y_test, self.svm_prediction))\n",
        "    print(confusion_matrix(self.y_test, self.svm_prediction))\n",
        "\n",
        "  def naive_bayes_model(self):\n",
        "    nb_train_input = self.train_embedding + abs(np.amin(self.train_embedding))\n",
        "    self.nb_model = MultinomialNB()\n",
        "    self.nb_model.fit(nb_train_input, self.y_train)\n",
        "  \n",
        "  def Evaluate_naive_bayes(self):\n",
        "    nb_test_input = self.test_embedding + abs(np.amin(self.test_embedding))\n",
        "    self.nb_prediction = self.nb_model.predict(nb_test_input)\n",
        "    print(classification_report(self.y_test, self.nb_prediction))\n",
        "    print(confusion_matrix(self.y_test, self.nb_prediction))\n",
        "  \n",
        "  def feature_extraction(self):\n",
        "    scaler = StandardScaler()\n",
        "    self.train_dataset['svm_log_prob_0'] = pd.Series(self.svm_model.predict_proba(self.train_embedding)[::,0])\n",
        "    self.train_dataset['svm_log_prob_1'] = pd.Series(self.svm_model.predict_proba(self.train_embedding)[::,-1])\n",
        "    self.train_dataset['cnn_prob'] = pd.Series(self.cnn_model.predict(self.X_train, verbose = 1, batch_size = self.batch_size).T.ravel())\n",
        "    self.train_dataset['num_char'] = self.train_dataset['text'].apply(count_chars)\n",
        "    self.train_dataset['num_words'] = self.train_dataset['text'].apply(count_words)\n",
        "    self.train_dataset.fillna(value=0, inplace=True)\n",
        "    self.train_features = self.train_dataset[['svm_log_prob_0','svm_log_prob_1','num_words','num_words','like_count','retweet_count']].to_numpy()\n",
        "    self.train_features = scaler.fit_transform(self.train_features)\n",
        "    \n",
        "\n",
        "    self.test_dataset['svm_log_prob_0'] = pd.Series(self.svm_model.predict_proba(self.test_embedding)[::,0])\n",
        "    self.test_dataset['svm_log_prob_1'] = pd.Series(self.svm_model.predict_proba(self.test_embedding)[::,-1])\n",
        "    self.test_dataset['cnn_prob'] = pd.Series(self.cnn_model.predict(self.X_test, verbose = 1, batch_size = self.batch_size).T.ravel())\n",
        "    self.test_dataset['num_char'] = self.test_dataset['text'].apply(count_chars)\n",
        "    self.test_dataset['num_words'] = self.test_dataset['text'].apply(count_words)\n",
        "    self.test_dataset.fillna(value=0, inplace=True)\n",
        "    self.test_features = self.test_dataset[['svm_log_prob_0','svm_log_prob_1','num_words','num_words','like_count','retweet_count']].to_numpy()\n",
        "    self.test_features = scaler.fit_transform(self.test_features)\n",
        "\n",
        "  def final_classifier(self):\n",
        "    self.final_DT = DecisionTreeClassifier().fit(self.train_features, self.y_train)\n",
        "    self.final_DT_prediction = self.final_DT.predict(self.test_features)\n",
        "    print(classification_report(self.y_test, self.final_DT_prediction))\n",
        "    print(confusion_matrix(self.y_test, self.final_DT_prediction))\n",
        "\n",
        "\n",
        "  def Main(self):\n",
        "    # print('----------- Training of SVM Model Starts -----------')\n",
        "    # print()\n",
        "    # self.svm_model()\n",
        "    # print()\n",
        "    # print('----------- Evaluation of SVM Model Starts -----------')\n",
        "    # print()\n",
        "    # self.Evaluate_svm()\n",
        "    # print()\n",
        "    # print('----------- Training of NB Model Starts -----------')\n",
        "    # print()\n",
        "    # self.naive_bayes_model()\n",
        "    # print()\n",
        "    # print('----------- Evaluation of NB Model Starts -----------')\n",
        "    # print()\n",
        "    # self.Evaluate_naive_bayes()\n",
        "    self.define_cnn_model()\n",
        "    print()\n",
        "    print('----------- Training of CNN Model Starts -----------')\n",
        "    print()    \n",
        "    self.train_cnn()\n",
        "    self.plot_cnn_training_history()\n",
        "    print()\n",
        "    print('----------- Evaluation of CNN Model Starts -----------')\n",
        "    print()\n",
        "    self.Evaluate_cnn()\n",
        "    # self.feature_extraction()\n",
        "    # self.final_classifier()\n",
        "    # self.save_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udh9G3-EcBuK"
      },
      "source": [
        "## Predict Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_9LH8yvuwbXq"
      },
      "outputs": [],
      "source": [
        "class Predict:\n",
        "  \n",
        "  def __init__(self,\n",
        "               \n",
        "               SVM_model_game,\n",
        "               CNN_model_game,\n",
        "               game_train_text,\n",
        "\n",
        "               SVM_model_celebrity,\n",
        "               CNN_model_celebrity,\n",
        "               celebrity_train_text,\n",
        "               \n",
        "               SVM_model_crypto,\n",
        "               CNN_model_crypto,\n",
        "               crypto_train_text,\n",
        "\n",
        "               SVM_model_environment,\n",
        "               CNN_model_environment,\n",
        "               environment_train_text,\n",
        "\n",
        "               ParsBert\n",
        "               ):\n",
        "\n",
        "        self.SVM_model_game = SVM_model_game\n",
        "        self.CNN_model_game = CNN_model_game\n",
        "        self.game_train_text = game_train_text\n",
        "\n",
        "        self.SVM_model_celebrity = SVM_model_celebrity\n",
        "        self.CNN_model_celebrity = CNN_model_celebrity\n",
        "        self.celebrity_train_text = celebrity_train_text\n",
        "\n",
        "        self.SVM_model_crypto = SVM_model_crypto\n",
        "        self.CNN_model_crypto = CNN_model_crypto\n",
        "        self.crypto_train_text = crypto_train_text\n",
        "        \n",
        "        self.SVM_model_environment = SVM_model_environment\n",
        "        self.CNN_model_environment = CNN_model_environment\n",
        "        self.environment_train_text = environment_train_text\n",
        "\n",
        "        self.ParsBert = ParsBert\n",
        "  \n",
        "  def feature_extrction(self, pp_text, category):\n",
        "    text_embedding = self.ParsBert.encode(pp_text)\n",
        "    tokenizer = text.Tokenizer()\n",
        "\n",
        "    if category == 'game':\n",
        "      tokenizer.fit_on_texts(list(self.game_train_text))\n",
        "    elif category == 'celebrity':\n",
        "      tokenizer.fit_on_texts(list(self.celebrity_train_text))\n",
        "    elif category == 'crypto':\n",
        "      tokenizer.fit_on_texts(list(self.crypto_train_text))\n",
        "    elif category == 'environment':\n",
        "      tokenizer.fit_on_texts(list(self.environment_train_text))\n",
        "\n",
        "    text_input = tokenizer.texts_to_sequences([pp_text])\n",
        "    encoded_text = sequence.pad_sequences(text_input, maxlen = len(pp_text))\n",
        "    return text_embedding, encoded_text\n",
        "\n",
        "  def Main(self):\n",
        "    while True:\n",
        "      sample = input('Please Enter your Text (Or Enter Quit): ')\n",
        "      if sample == 'Quit':\n",
        "        break\n",
        "      category = input('Enter Category of Text (game/ celebrity/ crypto/ environment): ')\n",
        "      \n",
        "      start_time = time.time()\n",
        "      sample = clean_tweet(sample)\n",
        "      text_embedding, encoded_text = self.feature_extrction(sample,category)\n",
        "\n",
        "      if category == 'game':\n",
        "        cnn_prediction = self.CNN_model_game.predict(encoded_text, verbose = 1, batch_size = 128)\n",
        "        svm_prediction = self.SVM_model_game.predict(text_embedding.reshape(-1, 768))\n",
        "        end_time = time.time()\n",
        "        print('input text: ',clean_tweet(sample))\n",
        "        print('CNN model output: ', cnn_prediction)\n",
        "        print('SVM model output: ', svm_prediction)\n",
        "        print('Time Duration:',(end_time - start_time),'Seconds')\n",
        "      \n",
        "      elif category == 'celebrity':\n",
        "        cnn_prediction = self.CNN_model_celebrity.predict(encoded_text, verbose = 1, batch_size = 128)\n",
        "        svm_prediction = self.SVM_model_celebrity.predict(text_embedding.reshape(-1, 768))\n",
        "        end_time = time.time()\n",
        "        print('input text: ',clean_tweet(sample))\n",
        "        print('CNN model output: ', cnn_prediction)\n",
        "        print('SVM model output: ', svm_prediction)\n",
        "        print('Time Duration:',(end_time - start_time),'Seconds')\n",
        "      \n",
        "      elif category == 'crypto':\n",
        "        cnn_prediction = self.CNN_model_crypto.predict(encoded_text, verbose = 1, batch_size = 128)\n",
        "        svm_prediction = self.SVM_model_crypto.predict(text_embedding.reshape(-1, 768))\n",
        "        end_time = time.time()\n",
        "        print('input text: ',clean_tweet(sample))\n",
        "        print('CNN model output: ', cnn_prediction)\n",
        "        print('SVM model output: ', svm_prediction)\n",
        "        print('Time Duration:',(end_time - start_time),'Seconds')\n",
        "      \n",
        "      elif category == 'environment':\n",
        "        cnn_prediction = self.CNN_model_environment.predict(encoded_text, verbose = 1, batch_size = 128)\n",
        "        svm_prediction = self.SVM_model_environment.predict(text_embedding.reshape(-1, 768))\n",
        "        end_time = time.time()\n",
        "        print('input text: ',clean_tweet(sample))\n",
        "        print('CNN model output: ', cnn_prediction)\n",
        "        print('SVM model output: ', svm_prediction)\n",
        "        print('Time Duration:',(end_time - start_time),'Seconds')\n",
        "      \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xtf6CJwKTlTG"
      },
      "source": [
        "## Game Event Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4A8IGc2GTlTH"
      },
      "outputs": [],
      "source": [
        "Game_dataset = DatasetLabeling(\n",
        "               '/content/gdrive/MyDrive/Event Detection Final Dataset/Game.csv',list_of_game_positive_keyphrase,[],spam_keyphrase)\n",
        "Game_dataset.Main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "dMFKWhM_TlTH"
      },
      "outputs": [],
      "source": [
        "Game_processed = DataProcessor(Game_dataset.labeled_dataset,\n",
        "                               Pars_Bert_Model,\n",
        "                               Down_Sampleing_Factor=1.5,\n",
        "                               Split_Factor=0.2)\n",
        "Game_processed.Main()\n",
        "del Game_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMFE1-AeTliD"
      },
      "source": [
        "## Celebrity Event Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rNCNR-Gs_wIU"
      },
      "outputs": [],
      "source": [
        "Celebrity_dataset = DatasetLabeling(\n",
        "               '/content/gdrive/MyDrive/Event Detection Final Dataset/Celebrity.csv',list_of_celebrity_positive_keyphrase,[],spam_keyphrase)\n",
        "Celebrity_dataset.Main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "6nKAxYK2_wIV"
      },
      "outputs": [],
      "source": [
        "Celebrity_processed = DataProcessor(Celebrity_dataset.labeled_dataset,\n",
        "                                    Pars_Bert_Model,\n",
        "                                    Down_Sampleing_Factor=1.5,\n",
        "                                    Split_Factor=0.2)\n",
        "Celebrity_processed.Main()\n",
        "del Celebrity_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIJSNBLHTlo_"
      },
      "source": [
        "## Crypto Event Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "AxtL0FO8Tlo_"
      },
      "outputs": [],
      "source": [
        "Crypto_dataset = DatasetLabeling(\n",
        "               '/content/gdrive/MyDrive/Event Detection Final Dataset/Crypto.csv',list_of_crypto_positive_keyphrase,[],spam_keyphrase)\n",
        "Crypto_dataset.Main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "4FCbjlleTlo_"
      },
      "outputs": [],
      "source": [
        "Crypto_processed = DataProcessor(Crypto_dataset.labeled_dataset,\n",
        "                                 Pars_Bert_Model,\n",
        "                                 Down_Sampleing_Factor=1.5,\n",
        "                                 Split_Factor=0.2)\n",
        "Crypto_processed.Main()\n",
        "del Crypto_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0Ur7ic6TkFh"
      },
      "source": [
        "## Environment Event Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Po5fDQLHTkFi"
      },
      "outputs": [],
      "source": [
        "Environment_dataset = DatasetLabeling(\n",
        "               '/content/gdrive/MyDrive/Event Detection Final Dataset/Environment.csv',list_of_environment_positive_keyphrase,[],spam_keyphrase)\n",
        "Environment_dataset.Main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Rctm-0MhTkFi"
      },
      "outputs": [],
      "source": [
        "Environment_processed = DataProcessor(Environment_dataset.labeled_dataset,\n",
        "                              Pars_Bert_Model,\n",
        "                              Down_Sampleing_Factor=1.5,\n",
        "                              Split_Factor=0.2)\n",
        "Environment_processed.Main()\n",
        "del Environment_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MM7ZIEzhH9S"
      },
      "source": [
        "## Load models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "import pickle"
      ],
      "metadata": {
        "id": "VBQTZNqUIfE7"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_file = open('/content/gdrive/MyDrive/Event_Detection_Models/Game_cnn_model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "CNN_model_game = model_from_json(loaded_model_json)\n",
        "CNN_model_game.load_weights(\"/content/gdrive/MyDrive/Event_Detection_Models/Game_cnn_model.h5\")\n",
        "SVM_model_game = pickle.load(open('/content/gdrive/MyDrive/Event_Detection_Models/Game_svm_model', 'rb'))\n",
        "print(\"Model Loaded\")\n"
      ],
      "metadata": {
        "id": "Df-b_sZlIkmV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21073e70-42b3-4651-e824-e171d71df05c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e8b3d81-4d79-4b4f-dda2-ac119cb66373",
        "id": "dOkN-x44IkmV"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Loaded\n"
          ]
        }
      ],
      "source": [
        "json_file = open('/content/gdrive/MyDrive/Event_Detection_Models/Celebrity_cnn_model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "CNN_model_celebrity = model_from_json(loaded_model_json)\n",
        "CNN_model_celebrity.load_weights(\"/content/gdrive/MyDrive/Event_Detection_Models/Celebrity_cnn_model.h5\")\n",
        "SVM_model_celebrity = pickle.load(open('/content/gdrive/MyDrive/Event_Detection_Models/Celebrity_svm_model', 'rb'))\n",
        "print(\"Model Loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "691tjL-eIkt3",
        "outputId": "c42724c8-b23e-4de2-ef5c-5088c07fe345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Loaded\n"
          ]
        }
      ],
      "source": [
        "json_file = open('/content/gdrive/MyDrive/Event_Detection_Models/Crypto_cnn_model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "CNN_model_crypto = model_from_json(loaded_model_json)\n",
        "CNN_model_crypto.load_weights(\"/content/gdrive/MyDrive/Event_Detection_Models/Crypto_cnn_model.h5\")\n",
        "SVM_model_crypto = pickle.load(open('/content/gdrive/MyDrive/Event_Detection_Models/Crypto_svm_model', 'rb'))\n",
        "print(\"Model Loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SiI0YjSIkt4",
        "outputId": "3b55f449-7f1d-49f8-e726-d76575f3138b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Loaded\n"
          ]
        }
      ],
      "source": [
        "json_file = open('/content/gdrive/MyDrive/Event_Detection_Models/Environment_cnn_model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "CNN_model_environment = model_from_json(loaded_model_json)\n",
        "CNN_model_environment.load_weights(\"/content/gdrive/MyDrive/Event_Detection_Models/Environment_cnn_model.h5\")\n",
        "SVM_model_environment = pickle.load(open('/content/gdrive/MyDrive/Event_Detection_Models/Environment_svm_model', 'rb'))\n",
        "print(\"Model Loaded\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMd7AoGxcmnQ"
      },
      "source": [
        "## Real-Time Simulation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Real_time_Prediction = Predict(\n",
        "\n",
        "               SVM_model_game,\n",
        "               CNN_model_game,\n",
        "               Game_processed.train_text,\n",
        "\n",
        "               SVM_model_celebrity,\n",
        "               CNN_model_celebrity,\n",
        "               Celebrity_processed.train_text,\n",
        "\n",
        "               SVM_model_crypto,\n",
        "               CNN_model_crypto,\n",
        "               Crypto_processed.train_text,\n",
        "\n",
        "               SVM_model_environment,\n",
        "               CNN_model_environment,\n",
        "               Environment_processed.train_text,\n",
        "\n",
        "               Pars_Bert_Model\n",
        "               )"
      ],
      "metadata": {
        "id": "ZxKYo15xKTZo"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "quLFkRRBclRY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8b5d56fb-cc9b-4e29-9b93-4b843b1909af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please Enter your Text (Or Enter Quit): یوبیسافت نسخه جدیدی از بازی محبوب اساسینس کرید رونمایی کرد\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): game\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "input text:  یوبیسافت نسخه جدیدی از بازی محبوب اساسینس کرید رونمایی کرد\n",
            "CNN model output:  [[0.5022783]]\n",
            "SVM model output:  [1]\n",
            "Time Duration: 12.989587306976318 Seconds\n",
            "Please Enter your Text (Or Enter Quit): خاطرات شمال محاله یادم بره\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): environment\n",
            "1/1 [==============================] - 0s 187ms/step\n",
            "input text:  خاطرات شمال محاله یادم بره\n",
            "CNN model output:  [[1.]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 1.06791353225708 Seconds\n",
            "Please Enter your Text (Or Enter Quit): با توجه به سیل اخیر چشمه کوهرنگ همدان با مشکل حدی مواجه شده است\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): environment\n",
            "1/1 [==============================] - 0s 135ms/step\n",
            "input text:  با توجه به سیل اخیر چشمه کوهرنگ همدان با مشکل حدی مواجه شده است\n",
            "CNN model output:  [[0.71500117]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.994037389755249 Seconds\n",
            "Please Enter your Text (Or Enter Quit): یکی از قلاده های پلنگ ایرانی مرد\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): environment\n",
            "1/1 [==============================] - 0s 150ms/step\n",
            "input text:  یکی از قلاده‌های پلنگ ایرانی مرد\n",
            "CNN model output:  [[0.17787682]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 1.009671926498413 Seconds\n",
            "Please Enter your Text (Or Enter Quit): برداشت عسل کوهی به محیط زیست آسیب جدی خواهد زد\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): environment\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "input text:  برداشت عسل کوهی به محیط زیست آسیب جدی خواهد زد\n",
            "CNN model output:  [[0.54271466]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.8729734420776367 Seconds\n",
            "Please Enter your Text (Or Enter Quit): لطفا از خرید و نگهداری سنجاب ها در قفس خودداری کنید\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): environment\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "input text:  لطفا از خرید و نگهداری سنجاب‌ها در قفس خودداری کنید\n",
            "CNN model output:  [[0.7069169]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.8977506160736084 Seconds\n",
            "Please Enter your Text (Or Enter Quit): شنیده ها از مردم محلی حاکی از وقوع سیل دارد\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): environment\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "input text:  شنیده‌ها از مردم محلی حاکی از وقوع سیل دارد\n",
            "CNN model output:  [[0.65157336]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.8784730434417725 Seconds\n",
            "Please Enter your Text (Or Enter Quit): هواشناسی چرا هشداری نداده بود؟\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): environment\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "input text:  هواشناسی چرا هشداری نداده بود\n",
            "CNN model output:  [[0.17529589]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 1.5458762645721436 Seconds\n",
            "Please Enter your Text (Or Enter Quit): هشت هکتار از جنگل های هیرکانی سوخت\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): environment\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "input text:  هشت هکتار از جنگل‌های هیرکانی سوخت\n",
            "CNN model output:  [[0.65463066]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.8799099922180176 Seconds\n",
            "Please Enter your Text (Or Enter Quit): آپارات گیم تعطیل شد\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): game\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f055dbb1d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 156ms/step\n",
            "input text:  آپارات گیم تعطیل شد\n",
            "CNN model output:  [[0.09170359]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.9477133750915527 Seconds\n",
            "Please Enter your Text (Or Enter Quit): بازی های انحصاری ماکروسافت در راه هستند\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): game\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f055dbb1d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 127ms/step\n",
            "input text:  بازی‌های انحصاری ماکروسافت در راه هستند\n",
            "CNN model output:  [[0.94210124]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.854886531829834 Seconds\n",
            "Please Enter your Text (Or Enter Quit): چرا همه گیمر های معروف از ایران مهاجرت کرده اند\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): game\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "input text:  چرا همه گیمر‌های معروف از ایران مهاجرت کرده‌اند\n",
            "CNN model output:  [[0.20235081]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.7329728603363037 Seconds\n",
            "Please Enter your Text (Or Enter Quit): عکس های منتشر شده از مهدی طارمی و سخر قریشی نشان دهنده رابطه این دو نفر هست\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): celebrity\n",
            "1/1 [==============================] - 0s 175ms/step\n",
            "input text:  عکس‌های منتشر شده از مهدی طارمی و سخر قریشی نشان دهنده رابطه این دو نفر هست\n",
            "CNN model output:  [[0.90809447]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.7453086376190186 Seconds\n",
            "Please Enter your Text (Or Enter Quit): وجود مافیا در سینمای ایران یک دروغ محصض است\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): celebrity\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "input text:  وجود مافیا در سینمای ایران یک دروغ محصض است\n",
            "CNN model output:  [[0.02301355]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.6152770519256592 Seconds\n",
            "Please Enter your Text (Or Enter Quit): وجود مافیا در سینمای ایران یک دروغ بزرگ است\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): celebrity\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "input text:  وجود مافیا در سینمای ایران یک دروغ بزرگ است\n",
            "CNN model output:  [[0.098136]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.5496869087219238 Seconds\n",
            "Please Enter your Text (Or Enter Quit): جمع زیادی از هنرمندان در مراسم دیروز شرکت کردند\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): celebrity\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "input text:  جمع زیادی از هنرمندان در مراسم دیروز شرکت کردند\n",
            "CNN model output:  [[0.12898917]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.6318089962005615 Seconds\n",
            "Please Enter your Text (Or Enter Quit): سیلی محکم ویل اسمیت در فضای مجازی وایرال شد\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): celebrity\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "input text:  سیلی محکم ویل اسمیت در فضای مجازی وایرال شد\n",
            "CNN model output:  [[0.93730116]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.5560092926025391 Seconds\n",
            "Please Enter your Text (Or Enter Quit): هر جای اینستاگرام رو که نگاه میکنی فیم سیلی ویل اسمیت رو میبینی\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): celebrity\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "input text:  هر جای اینستاگرام رو که نگاه میکنی فیم سیلی ویل اسمیت رو میبینی\n",
            "CNN model output:  [[0.99891543]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.5509538650512695 Seconds\n",
            "Please Enter your Text (Or Enter Quit): هر جای اینستاگرام رو که نگاه میکنی فیلم سیلی ویل اسمیت رو میبینی\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): celebrity\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "input text:  هر جای اینستاگرام رو که نگاه میکنی فیلم سیلی ویل اسمیت رو میبینی\n",
            "CNN model output:  [[1.]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.5829777717590332 Seconds\n",
            "Please Enter your Text (Or Enter Quit): نهنگ ها بیدار شدن و همه دوج کوین هایی که خریده بودند رو فروختند\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): crypto\n",
            "1/1 [==============================] - 0s 106ms/step\n",
            "input text:  نهنگ‌ها بیدار شدن و همه دوج کوین هایی که خریده بودند رو فروختند\n",
            "CNN model output:  [[0.3920986]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.9868206977844238 Seconds\n",
            "Please Enter your Text (Or Enter Quit): خرید شت کوین بنظرتون منطقیه؟\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): crypto\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "input text:  خرید شت کوین بنظرتون منطقیه\n",
            "CNN model output:  [[0.9999995]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 1.0121171474456787 Seconds\n",
            "Please Enter your Text (Or Enter Quit): چرا ملت ایران بدون هیچ درکی از بازار های مالی واارد اون میشن\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): crypto\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "input text:  چرا ملت ایران بدون هیچ درکی از بازار‌های مالی واارد اون میشن\n",
            "CNN model output:  [[0.9071477]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.9984221458435059 Seconds\n",
            "Please Enter your Text (Or Enter Quit): شما اگه پول داشته باشید کدوم رو میخرید؟\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): crypto\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "input text:  شما اگه پول داشته باشید کدوم رو میخرید\n",
            "CNN model output:  [[0.9999051]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.8929340839385986 Seconds\n",
            "Please Enter your Text (Or Enter Quit): نظرتون چیه ؟ بیت کوین یا شیبا\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): crypto\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "input text:  نظرتون چیه بیت کوین یا شیبا\n",
            "CNN model output:  [[0.99777347]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.8964581489562988 Seconds\n",
            "Please Enter your Text (Or Enter Quit): صرافی بایننس ایرانی هارو تحریم کرد\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): crypto\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "input text:  صرافی بایننس ایرانی هارو تحریم کرد\n",
            "CNN model output:  [[0.07920744]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.8999021053314209 Seconds\n",
            "Please Enter your Text (Or Enter Quit): دسترسی ایرانی ها به صرافی بایننس محدود شد\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): crypto\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "input text:  دسترسی ایرانی‌ها به صرافی بایننس محدود شد\n",
            "CNN model output:  [[0.16164008]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.9183337688446045 Seconds\n",
            "Please Enter your Text (Or Enter Quit): هر بچه ای رو که میبینی رفته تو کار کریپتو\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): crypto\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "input text:  هر بچه‌ای رو که میبینی رفته تو کار کریپتو\n",
            "CNN model output:  [[0.1774854]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.8867614269256592 Seconds\n",
            "Please Enter your Text (Or Enter Quit): هرکی از مامانش قهر میکنه میاد سمت بازار های مالی\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): crypto\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "input text:  هرکی از مامانش قهر میکنه میاد سمت بازار‌های مالی\n",
            "CNN model output:  [[0.99976]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.9381730556488037 Seconds\n",
            "Please Enter your Text (Or Enter Quit): بازار های مالی\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): crypto\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "input text:  بازار‌های مالی\n",
            "CNN model output:  [[nan]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.9378519058227539 Seconds\n",
            "Please Enter your Text (Or Enter Quit): خرید مرغ برای ایرانی ها  کار خوبیه\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): crypto\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "input text:  خرید مرغ برای ایرانی‌ها کار خوبیه\n",
            "CNN model output:  [[0.02032468]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.8876121044158936 Seconds\n",
            "Please Enter your Text (Or Enter Quit): خرید سکه سود خوبی داره\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): crypto\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "input text:  خرید سکه سود خوبی داره\n",
            "CNN model output:  [[0.99999964]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.9811592102050781 Seconds\n",
            "Please Enter your Text (Or Enter Quit): شاخص کل بورس ایران به پایین ترین حد خودش در یک سال اخیر رسید\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): crypto\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "input text:  شاخص کل بورس ایران به پایین‌ترین حد خودش در یک سال اخیر رسید\n",
            "CNN model output:  [[0.9999999]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.9154219627380371 Seconds\n",
            "Please Enter your Text (Or Enter Quit): مردم جلوی اتاق بورس ایران تجمع کردند\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): crypto\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "input text:  مردم جلوی اتاق بورس ایران تجمع کردند\n",
            "CNN model output:  [[0.7250355]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.909564733505249 Seconds\n",
            "Please Enter your Text (Or Enter Quit): همگی فردا جلوی کارگزاری مفید جمع میشیم هرکی نیاد از ما نسیست\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): crypto\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "input text:  همگی فردا جلوی کارگزاری مفید جمع میشیم هرکی نیاد از ما نسیست\n",
            "CNN model output:  [[0.96507615]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.9013075828552246 Seconds\n",
            "Please Enter your Text (Or Enter Quit): این چه وضعشه اینا دولت از بورس حمایت میکنه ملتم بیشتر میرن میخرن\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): crypto\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "input text:  این چه وضعشه اینا دولت از بورس حمایت میکنه ملتم بیشتر میرن میخرن\n",
            "CNN model output:  [[0.91401994]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.8918664455413818 Seconds\n",
            "Please Enter your Text (Or Enter Quit): عکس های منشر شده از فلانی\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): celebrity\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "input text:  عکس‌های منشر شده از فلانی\n",
            "CNN model output:  [[0.04057676]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.7136576175689697 Seconds\n",
            "Please Enter your Text (Or Enter Quit): کشف حجاب کار خوبی نیست\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): celebrity\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "input text:  کشف حجاب کار خوبی نیست\n",
            "CNN model output:  [[0.96852106]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.5423164367675781 Seconds\n",
            "Please Enter your Text (Or Enter Quit): کم کم همه بازیگرای ایرانی دارن میرن ترکیه\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): celebrity\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "input text:  کم کم همه بازیگرای ایرانی دارن میرن ترکیه\n",
            "CNN model output:  [[0.99994695]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.5424318313598633 Seconds\n",
            "Please Enter your Text (Or Enter Quit): رونالدو از هتل جدیدش توی پرتغال رونمایی کرد\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): celebrity\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "input text:  رونالدو از هتل جدیدش توی پرتغال رونمایی کرد\n",
            "CNN model output:  [[0.2181104]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.5466461181640625 Seconds\n",
            "Please Enter your Text (Or Enter Quit): غلط کرده هرکی کشف حجاب کنه\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): celebrity\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "input text:  غلط کرده هرکی کشف حجاب کنه\n",
            "CNN model output:  [[0.9994499]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.5778982639312744 Seconds\n",
            "Please Enter your Text (Or Enter Quit): ماکروسافت شرکت اکتیویژن رو خرید\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): game\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "input text:  ماکروسافت شرکت اکتیویژن رو خرید\n",
            "CNN model output:  [[0.999908]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.8095695972442627 Seconds\n",
            "Please Enter your Text (Or Enter Quit): ماکروسافت شرکت اکتیویژن رو تصاحب کرد\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): game\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "input text:  ماکروسافت شرکت اکتیویژن رو تصاحب کرد\n",
            "CNN model output:  [[0.99942684]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.7275276184082031 Seconds\n",
            "Please Enter your Text (Or Enter Quit): کدوم بهتره سونی یا ماکروسافت\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): game\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "input text:  کدوم بهتره سونی یا ماکروسافت\n",
            "CNN model output:  [[0.1033169]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.7677288055419922 Seconds\n",
            "Please Enter your Text (Or Enter Quit): ماکروسافت رفت نون خرید\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): game\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "input text:  ماکروسافت رفت نون خرید\n",
            "CNN model output:  [[0.9762247]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.7317874431610107 Seconds\n",
            "Please Enter your Text (Or Enter Quit): نمیدونم چرا خیلیا میگن جنگ بعدی جنگ ابه؟\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): environment\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "input text:  نمیدونم چرا خیلیا میگن جنگ بعدی جنگ ابه\n",
            "CNN model output:  [[0.99999964]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.8262083530426025 Seconds\n",
            "Please Enter your Text (Or Enter Quit): توی قطحی سال 1270 فقط شمال ایران زنده موند\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): environment\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "input text:  توی قطحی سال فقط شمال ایران زنده موند\n",
            "CNN model output:  [[0.9998778]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.8438143730163574 Seconds\n",
            "Please Enter your Text (Or Enter Quit): صید ترال هر زور داره بیشتر و بیشتر میشه\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): environment\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "input text:  صید ترال هر زور داره بیشتر و بیشتر میشه\n",
            "CNN model output:  [[0.32560045]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.8212857246398926 Seconds\n",
            "Please Enter your Text (Or Enter Quit): کسی نمیخواد جلوی صید ترال رو بگیره\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): environment\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "input text:  کسی نمیخواد جلوی صید ترال رو بگیره\n",
            "CNN model output:  [[0.15713993]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.8221757411956787 Seconds\n",
            "Please Enter your Text (Or Enter Quit): چرا دریای چابهار رو اجاره دادید به چینی ها\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): environment\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "input text:  چرا دریای چابهار رو اجاره دادید به چینی‌ها\n",
            "CNN model output:  [[0.0971138]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.8383142948150635 Seconds\n",
            "Please Enter your Text (Or Enter Quit): دیگه تموم شد دورانی که به بورس اعتماد میکردن\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): crypto\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "input text:  دیگه تموم شد دورانی که به بورس اعتماد میکردن\n",
            "CNN model output:  [[0.67607427]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.9516527652740479 Seconds\n",
            "Please Enter your Text (Or Enter Quit): دیگه تموم شد اون دوران. الان فقط کریپتو\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): crypto\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "input text:  دیگه تموم شد اون دوران الان فقط کریپتو\n",
            "CNN model output:  [[0.9988708]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.8970766067504883 Seconds\n",
            "Please Enter your Text (Or Enter Quit): دیگه تموم شد اون دوران الان فقط سکه\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): crypto\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "input text:  دیگه تموم شد اون دوران الان فقط سکه\n",
            "CNN model output:  [[0.99072814]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.9092051982879639 Seconds\n",
            "Please Enter your Text (Or Enter Quit): دیگه تموم شد اون دوران الان فقط\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): crypot\n",
            "Please Enter your Text (Or Enter Quit): دیگه تموم شد اون دوران الان فقط\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): crypto\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "input text:  دیگه تموم شد اون دوران الان فقط\n",
            "CNN model output:  [[0.9850129]]\n",
            "SVM model output:  [0]\n",
            "Time Duration: 0.9131307601928711 Seconds\n",
            "Please Enter your Text (Or Enter Quit): دیگه تموم شد\n",
            "Enter Category of Text (game/ celebrity/ crypto/ environment): crypto\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-58da7e532355>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mReal_time_Prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-73267250161c>\u001b[0m in \u001b[0;36mMain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'crypto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mcnn_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCNN_model_crypto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0msvm_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVM_model_crypto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_15/conv1d_47/Conv1D' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 1233, in inner\n      self.run()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 1147, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n      yield self.process_one()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 346, in wrapper\n      runner = Runner(result, future, yielded)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 1080, in __init__\n      self.run()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 1147, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n      user_expressions, allow_stdin,\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n      raw_cell, store_history, silent, shell_futures)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-39-58da7e532355>\", line 1, in <module>\n      Real_time_Prediction.Main()\n    File \"<ipython-input-24-73267250161c>\", line 89, in Main\n      cnn_prediction = self.CNN_model_crypto.predict(encoded_text, verbose = 1, batch_size = 128)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1982, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step\n      outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n      return self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\", line 240, in convolution_op\n      name=self.__class__.__name__)\nNode: 'sequential_15/conv1d_47/Conv1D'\nComputed output size would be negative: -1 [input_size: 1, effective_filter_size: 3, stride: 1]\n\t [[{{node sequential_15/conv1d_47/Conv1D}}]] [Op:__inference_predict_function_3100]"
          ]
        }
      ],
      "source": [
        "Real_time_Prediction.Main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HXx4HbvvUNjw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "O0ixs3gMPfGS",
        "UjmLd8KFafKP",
        "haJgbMelaqGH",
        "tBiC_-_2a7jN",
        "8NioYnygWlzf",
        "ihTbRnJtXcSm",
        "tzfOvmZWW49y",
        "_RQwJqwjW5Cj",
        "2z8pPJwZW5IC",
        "D0euC6vyW5Nq",
        "yVHC2-q8XLU8",
        "P0cet-mCXLb9",
        "i3HWWCU5XLfU",
        "TbFnqfZyXLia",
        "9hzQXpUWXLln",
        "iquYqQDuYQ90",
        "MFEdaTPFW5bc",
        "Oj0xvKy5bIY8",
        "zs1AcBh3bw2S",
        "p0oUl8UXb2Ji",
        "XVJGRFiWb8G6",
        "Udh9G3-EcBuK",
        "Xtf6CJwKTlTG",
        "PMFE1-AeTliD",
        "oIJSNBLHTlo_",
        "N0Ur7ic6TkFh",
        "1MM7ZIEzhH9S"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}